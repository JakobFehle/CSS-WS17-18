dict<-generateDictionary(twitter_data_sentiment_match$text,response, language="german", modelType = "lasso", minWordLength = 3)
twitter_data_sentiment$text <- iconv(twitter_data_sentiment$text, to = "utf-8")
View(twitter_data_sentiment)
twitter_data_sentiment<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
twitter_data_sentiment$text <- iconv(twitter_data_sentiment$text, to = "utf-8")
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_match<-twitter_data_sentiment%>%mutate(sentimentScore = as.numeric(sub(",", ".", sentimentScore, fixed = TRUE)))
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = as.numeric(sub(",", ".", sentimentScore, fixed = TRUE)))
twitter_data_sentiment<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
twitter_data_sentiment$text <- iconv(twitter_data_sentiment$text, to = "utf-8")
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = as.numeric(sub(",", ".", sentimentScore, fixed = TRUE)))
View(twitter_data_sentiment_match)
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(text=cleanTweetText(text))
text<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(twitter_data_sentiment_match$text,response, language="german", modelType = "lasso", minWordLength = 3)
source("r scripts/cleanTweetText.R")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(text=cleanTweetText(text))
text<-transformIntoCorpus(twitter_data_sentiment_match$text)
source("r scripts/cleanTweetText.R")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(text=cleanTweetText(text))
source("r scripts/cleanTweetText.R")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(text=cleanTweetText(text))
text<-stri_replace_all_fixed(text,
#c("ä", "ö", "ü", "Ä", "Ö", "Ü"),
c("\U00E4","\U00F6","\U00FC","\U00C4","\U00D6","\U00DC"),
c("ae", "oe", "ue", "Ae", "Oe", "Ue"), vectorize_all = FALSE)
source("r scripts/cleanTweetText.R")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(text=cleanTweetText(text))
text<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
response
dict<-generateDictionary(twitter_data_sentiment_match$text,response, language="german", modelType = "lasso", minWordLength = 3)
dict<-generateDictionary(text,response, language="german", modelType = "lasso", minWordLength = 3)
dict<-generateDictionary(text,response)
dict
dict<-generateDictionary(text,response,modelType = lasso)
dict<-generateDictionary(text,response,modelType = "lasso")
dict
summary(dict)
install.packages("tm")
library(tm)
library(spikeslab)
require(tidyverse)
require(dplyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
dict<-generateDictionary(x,response, language = "english",
modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.9, weighting = function(x)
tm::weightTfIdf(x, normalize = FALSE), ...)
dict<-generateDictionary(x,response, language = "english",
modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.9, weighting = function(x)
tm::weightTfIdf(x, normalize = FALSE))
View(twitter_data_sentiment)
twitter_data_sentiment<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(twitter_data_sentiment)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
View(twitter_data_sentiment)
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = as.numeric(sub(",", ".", sentimentScore, fixed = TRUE)))
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(text,response)
dict<-generateDictionary(x,response)
dict<-generateDictionary(x,response, language = "german",
modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.9, weighting = function(x)
tm::weightTfIdf(x, normalize = FALSE))
dict<-generateDictionary(x,response, language = "german",
modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.9)
dict<-generateDictionary(x,response, language = "deutsch",
modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.9)
dict<-generateDictionary(x,response, language = "german",
modelType = "lasso", sparsity = 0.9)
dict<-generateDictionary(x,response, language = "german",
modelType = "lasso")
dict<-generateDictionary(x,response,
modelType = "lasso")
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.9, weighting)
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.9, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
dict<-generateDictionary(twitter_data_sentiment_match$text,response)
View(dict)
View(dict)
View(dict)
require(tidyverse)
require(dplyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
# Aufbereiten Twitter Datensatz
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
#Entfernt alle Links (http(s) und alle Zeichen bis zum nächsten Leerzeichen)
twitter_data$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data$text)
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
#Entfernt alle abgeschnittenen Links
twitter_data$text<-gsub("htt[p]?\U2026","",twitter_data$text)
#Entfernen von abgeschnittenen Tweets
c
# Aufbereiten für Random Sample
twitter_data<-twitter_data%>%mutate(sentimentScore=NA)
# NUR FÜR EXCEL!
twitter_data$text<-gsub(","," ",twitter_data$text)
twitter_data$text<-gsub(";"," ",twitter_data$text)
# Random Sample
twitter_data_frac<-twitter_data%>%sample_n(1000, replace=FALSE)
twitter_data_frac<-twitter_data_frac%>%select(ID,sentimentScore,text)
write.table(twitter_data_frac, "data/Twitter_Sentiment_TrainData.csv", sep = ",")
# Auswertung
# Einlesen
twitter_data_sentiment<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
# Spalten Säubern (ID leider verfälscht)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
# Fehlerhaft bei ä,ü,ö
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
# Säubern
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
# Nur Matches der Kreuzvalid.
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
# Umwandeln der Scores in numeric mit "."
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = as.numeric(sub(",", ".", sentimentScore, fixed = TRUE)))
# Testweise join für orginalen Text
# twitter_data_merge<-merge(x = twitter_data, y = twitter_data_sentiment, by = "text", all.x = TRUE)
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(twitter_data_sentiment_match$text,response)
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.9, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
install.packages("SentimentAnalysis")
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
dict<-generateDictionary(twitter_data_sentiment_match$text,response)
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.9, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
View(dict)
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
view(dict)
View(dict)
View(dict)
df <- data.frame(matrix(unlist(dict), nrow=132, byrow=T),stringsAsFactors=FALSE)
df <- data.frame(matrix(unlist(dict), nrow=132, byrow=T),stringsAsFactors=FALSE)
df <- ldply (dict, data.frame)
df <- ldply (dict, data.frame)
install.packages("plyr")
install.packages("plyr")
library(plyr)
require(plyr)
require(plyr)
df <- ldply (dict, data.frame)
require(tidyverse)
require(dplyr)
require(plyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
# Einlesen
twitter_data_sentiment_david<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(twitter_data_sentiment_jakob)
twitter_data_sentiment_jakob<-read_delim("data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob[,c(Nummer,ID,sentimentScore,isMatch,text)]
twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
View(twitter_data_sentiment_jakob)
twitter_data_sentiment_jakob<-read_delim("data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("data/SentimentAnalyseJakobMatchedFromDavid.csv",
",", escape_double = FALSE, trim_ws = TRUE)
View(twitter_data_sentiment_jakob)
twitter_data_sentiment_jakob<-read_delim("data/SentimentAnalyseJakobMatchedFromDavid.csv",
",", escape_double = FALSE, trim_ws = TRUE)
View(twitter_data_sentiment_jakob)
twitter_data_sentiment_jakob<-read_delim("data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(twitter_data_sentiment_jakob)
twitter_data_sentiment_jakob<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-read_delim("data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
View(twitter_data_sentiment_jakob)
twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
View(twitter_data_sentiment_jakob)
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
View(twitter_data_sentiment_jakob)
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
View(twitter_data_sentiment)
# Spalten Säubern (ID leider verfälscht)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
# Fehlerhaft bei ä,ü,ö
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
# Säubern
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
# Nur Matches der Kreuzvalid.
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
# Umwandeln der Scores in numeric mit "."
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = as.numeric(sub(",", ".", sentimentScore, fixed = TRUE)))
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
View(twitter_data_sentiment_match)
# Umwandeln der Scores in numeric mit "."
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))%>%mutate(sentimentScore = as.numeric(sentimentScore))
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
# Einlesen
twitter_data_sentiment_david<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
# Spalten Säubern (ID leider verfälscht)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
# Fehlerhaft bei ä,ü,ö
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
# Säubern
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
# Nur Matches der Kreuzvalid.
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
# Umwandeln der Scores in numeric mit "."
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
# Einlesen
twitter_data_sentiment_david<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
# Spalten Säubern (ID leider verfälscht)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
# Fehlerhaft bei ä,ü,ö
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
# Säubern
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
# Nur Matches der Kreuzvalid.
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
# Umwandeln der Scores in numeric mit "."
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))%>%
mutate(sentimentScore = as.numeric(sentimentScore))
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999)
View(text)
response
twitter_data_sentiment_match[,c("sentimentScore")]<-sapply([,c("sentimentScore")],as.numeric)
twitter_data_sentiment_match[,c("sentimentScore")]<-sapply(twitter_data_sentiment_match[,c("sentimentScore")],as.numeric)
View(twitter_data_sentiment_match)
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
twitter_data_sentiment_match[,"sentimentScore"]<-sapply(twitter_data_sentiment_match[,"sentimentScore"],as.numeric)
View(twitter_data_sentiment_match)
str(twitter_data_sentiment_match)
twitter_data_sentiment_match[,"sentimentScore"]<-sapply(twitter_data_sentiment_match[,"sentimentScore"],as.factor)
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
str(twitter_data_sentiment_match)
twitter_data_sentiment_match[,"sentimentScore"]<-sapply(twitter_data_sentiment_match[,"sentimentScore"],as.numeric)
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%filter(sentimentScore != "NA")
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
View(dict)
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE), language = "german")
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language =  "german")
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
View(x)
View(x)
x<-transformIntoCorpus(twitter_data_sentiment_match$text, language = "german")
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
cleanTweetText<-function(text){
require(stringr)
require(stringi)
hashtag_pattern <- "#([[:alnum:]]|[_])+"
mention_pattern <- "@([[:alnum:]]|[_])+"
strip_RT_pattern<-"RT\\s@([[:alnum:]]|[_])+:"
#Die URLs und Mentions werden entfernt
text<-str_replace_all(text,pattern=mention_pattern,replacement="")
#Wörter die weniger als 3 Zeichen haben müssen weg außer sie haben #
text<-str_replace_all(text,pattern="(?<!#)\\b[a-zA-Z0-9]{1,2}\\b",replacement = "")
#depends on whether you wanna keep hashtags or not
text<-str_replace_all(text,pattern="#",replacement="")
#Konvertierung von Umlauten
text<-stri_replace_all_fixed(text,
#c("?", "?", "?", "?", "?", "?"),
c("\U00E4","\U00F6","\U00FC","\U00C4","\U00D6","\U00DC"),
c("ae", "oe", "ue", "Ae", "Oe", "Ue"), vectorize_all = FALSE)
#Entfernung von Emoticons
text<-iconv(text, "latin1", "ASCII", sub="")
#Zahlen außer IN Hashtags
text<-str_replace_all(text,pattern="\\b\\d+\\b",replacement="")
#Satzzeichen und Special Characters außer # müssen weg
text<-str_replace_all(text,pattern="[^[:alnum:]#]",replacement=" ")
text<-str_to_lower(text)
return(text)
}
#checkCleaner<-c("This is a 💁 test #eu string .with @mention and #hashtag but d. u. also with http://www.ur.de !","And another string https://t.co/9aNUY4ZacF with to","we want; to keep #g20 or #r2g but, not 70 or 100 ...")
#cleanTweetText(checkCleaner)
checkCleaner<-c("This is a 💁 test #eu string .with @mention and #hashtag but d. u. also with http://www.ur.de !","And another string https://t.co/9aNUY4ZacF with to","we want; to keep #g20 or #r2g but, not 70 or 100 ...")
cleanTweetText(checkCleaner)
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
# Aufbereiten Twitter Datensatz
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
#Entfernt alle Links (http(s) und alle Zeichen bis zum nächsten Leerzeichen)
twitter_data$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data$text)
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
#Entfernt alle abgeschnittenen Links
twitter_data$text<-gsub("htt[p]?\U2026","",twitter_data$text)
#Entfernen von abgeschnittenen Tweets
twitter_data<-twitter_data[!grepl("\U2026", twitter_data_sentiment$text),]
#Entfernen von abgeschnittenen Tweets
twitter_data<-twitter_data[!grepl("\U2026", twitter_data$text),]
View(twitter_data)
cleanTweetText<-function(text){
require(stringr)
require(stringi)
hashtag_pattern <- "#([[:alnum:]]|[_])+"
mention_pattern <- "@([[:alnum:]]|[_])+"
strip_RT_pattern<-"RT\\s@([[:alnum:]]|[_])+:"
#Die URLs und Mentions werden entfernt
text<-str_replace_all(text,pattern=mention_pattern,replacement="")
#Wörter die weniger als 3 Zeichen haben müssen weg außer sie haben #
text<-str_replace_all(text,pattern="(?<!#)\\b[a-zA-Z0-9]{1,2}\\b",replacement = "")
#depends on whether you wanna keep hashtags or not
text<-str_replace_all(text,pattern="#",replacement="")
#Entfernung der Unicode Character <U+...>
test<-str_replace_all(text,pattern="\\<.?\\>",replacement="")
#Konvertierung von Umlauten
text<-stri_replace_all_fixed(text,
#c("?", "?", "?", "?", "?", "?"),
c("\U00E4","\U00F6","\U00FC","\U00C4","\U00D6","\U00DC"),
c("ae", "oe", "ue", "Ae", "Oe", "Ue"), vectorize_all = FALSE)
#Entfernung von Emoticons
text<-iconv(text, "latin1", "ASCII", sub="")
#Zahlen außer IN Hashtags
text<-str_replace_all(text,pattern="\\b\\d+\\b",replacement="")
#Satzzeichen und Special Characters außer # müssen weg
text<-str_replace_all(text,pattern="[^[:alnum:]#]",replacement=" ")
text<-str_to_lower(text)
return(text)
}
#checkCleaner<-c("This is a 💁 test #eu string .with @mention and #hashtag but d. u. also with http://www.ur.de !","And another string https://t.co/9aNUY4ZacF with to","we want; to keep #g20 or #r2g but, not 70 or 100 ...")
#cleanTweetText(checkCleaner)
#CleanTweetText auf den gesamten Twitter Datensatz
twitter_data<-twitter_data%>%mutate(text=cleanTweetText(text))
# Einlesen
twitter_data_sentiment_david<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
# Spalten Säubern (ID leider verfälscht)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
# Fehlerhaft bei ä,ü,ö
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
View(twitter_data_sentiment)
# Einlesen
twitter_data_sentiment_david<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
# Spalten Säubern (ID leider verfälscht)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
# Säubern
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
# Fehlerhaft bei ä,ü,ö
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
# Nur Matches der Kreuzvalid.
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
# Umwandeln der Scores in numeric mit "."
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment_match[,"sentimentScore"]<-sapply(twitter_data_sentiment_match[,"sentimentScore"],as.numeric)
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%filter(sentimentScore != "NA")
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
View(dict)
summary(dict)
dict
require(tidyverse)
require(dplyr)
require(plyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
dict_level3<-generateDictionary(x_level3,response_level3,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
baseline_dict_level3<-read_delim("data/SentimentForDict3LevelSkala.csv",
";", escape_double = FALSE, trim_ws = TRUE)
baseline_dict_level5<-read_delim("data/SentimentforDict5LevelSkala.csv",
";", escape_double = FALSE, trim_ws = FALSE)
#Erstellen des Dictornary auf Level 3 Baseline
x_level3<-transformIntoCorpus(sbaseline_dict_level3$text)
#Erstellen des Dictornary auf Level 3 Baseline
x_level3<-transformIntoCorpus(baseline_dict_level3$text)
response_level3<-as.numeric(as.character(baseline_dict_level3$sentimenScore))
dict_level3<-generateDictionary(x_level3,response_level3,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
#only selecting the text column for sentiment analyses
twitter_data_for_sentiment<-twitter_data%>%select("text")
#only selecting the text column for sentiment analyses
twitter_data_for_sentiment<-twitter_data%>%select("text")
twitter_data_for_sentiment<-twitter_data%>%select("text")
summary(dict_level3)
