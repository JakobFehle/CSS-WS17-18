twitter_data_cleaned1<-twitter_data_cleaned[1:120000,]
predict1<-predict(ridge_5lvl,twitter_data_cleaned1$text)
setwd("C:/Users/David/Downloads/Uni/CSS/projekt/CSS-WS17-18-master/r scripts")
require(tidyverse)
require(ggraph2)
library(gridExtra)
library(grid)
source('scripts/cleanHashtags.R')
source('cleanHashtags.R')
setwd("C:/Users/David/Downloads/Uni/CSS/projekt/CSS-WS17-18-master")
source('scripts/cleanHashtags.R')
source('r scripts/cleanTweetText.R')
source('r scripts/cleanHashtags.R')
twitter_data_sample<-read_csv("data/twitter_data_sample.csv",
locale = locale())
twitter_data_sample<-read_csv("twitter data/twitter_data.csv",
locale = locale())
# Anzahl Tweets als Retweets
twitter_data_retweets<-twitter_data_sample%>%filter(isRetweet==1)
nrow(twitter_data_retweets)
nrow(twitter_data_sample)
nrow(twitter_data_retweets)
nrow(twitter_data_quotes)
# Anzahl Tweets als Quotes
twitter_data_quotes<-twitter_data_sample%>%filter(isQuote==1)
nrow(twitter_data_quotes)
# Anzahl Tweets als Antworten auf andere Tweets
twitter_data_replies<-twitter_data_sample%>%filter(inReplyToUser!='null')
nrow(twitter_data_replies)
ggplot(twitter_data_quotes,twitter_data_replies,twitter_data_retweets)
ggplot(twitter_data_quotes,twitter_data_replies,twitter_data_retweets+aes())
ggplot(twitter_data_quotes,twitter_data_replies,twitter_data_retweets)+aes()
pplot <-ggplot(ddf,x=group, y=mean, aes(group,mean,fill=time))
pplot <-ggplot(twitter_data_sample%>%filter(inReplyToUser!='null'),x=group, y=mean, aes(group,mean,fill=time))
pplot +
geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymax = mean + se, ymin= mean - se), position = position_dodge(width=0.7), width=0.2) +
#geom_point(stat="identity", shape=21, size=5, position=position_dodge(width=0.7), width=0.2)
geom_point(stat="identity", shape=21, size=5, position=position_dodge(width=0.7))
p <-ggplot(twitter_data_sample%>%filter(isQuote==1), aes(class))
p + geom_bar()
p <-ggplot(twitter_data_sample%>%filter(isQuote==1), aes(isRetweet))
p + geom_bar()
nrow(twitter_data_retweets)
basic <-c("Retweet","Quotes","Answer")
basic
nrow(twitter_data_retweets)
values <-c(twitter_data_retweets,twitter_data_quotes,twitter_data_replies)
values
values <-c(nrow(twitter_data_retweets),nrow(twitter_data_quotes),nrow(twitter_data_replies))
values
basic_plot_data<-data.frame(basic,values)
basic_plot <- ggplot(basic_plot_data, aes(basic,values))
basic_plot <- ggplot(basic_plot_data, aes(basic,values)) + geom_bar()
basic_plot
basic_plot <- ggplot(basic_plot_data, aes(values,basic)) + geom_bar()
basic_plot
basic_plot <- ggplot(basic_plot_data, aes(values,basic))
basic_plot +geom_bar()
basic_plot <- ggplot(basic_plot_data, aes(y = values,x =basic))
basic_plot +geom_bar()
basic_plot +geom_bar(stat = "identity")
basic_plot +geom_bar(stat = "identity") + labs(x = "")
basic_plot +geom_bar(stat = "identity") + labs(x = "", y="Count of tweets")
basic_plot +geom_bar(stat = "identity") + labs(x = "", y="count of tweets")
basic_plot +geom_bar(stat = "identity", fill='#890E1C') + labs(x = "", y="count of tweets")
View(twitter_data)
# Timeline Tweets weeksTillElection
twitter_data_timeline<-twitter_data_sample%>%select(ID, party, retweetCount, weeksTillElection)
twitter_data_timeline<-twitter_data_timeline[order(twitter_data_timeline$weeksTillElection, decreasing=TRUE),]
twitter_data_timeline<-twitter_data_timeline%>%
group_by(party, weeksTillElection)%>%
summarise(count=n(),retweetCount=sum(retweetCount))
ggplot(twitter_data_timeline,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")
ggplot(twitter_data_timeline,aes(x=weeksTillElection,y=retweetCount))+
geom_bar(stat="identity", fill='#890E1C')+
ylab("Anzahl Retweets")+
xlab("Wochen bis zur Wahl")
ggplot(twitter_data_timeline,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity" ,fill='#890E1C')+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")
ggplot(twitter_data_timeline,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity" ,fill='#890E1C')+
ylab("count of tweets")+
xlab("Weeks until election")
ggplot(twitter_data_timeline,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity" ,fill='#890E1C')+
ylab("count of tweets")+
xlab("weeks until election")
twitter_data_timeline_afd<-twitter_data_timeline%>%filter(party=='AfD')
plot_timeline_afd<-ggplot(twitter_data_timeline_afd,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="AfD")
twitter_data_timeline_spd<-twitter_data_timeline%>%filter(party=='SPD')
plot_timeline_spd<-ggplot(twitter_data_timeline_spd,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="SPD")
twitter_data_timeline_cdu<-twitter_data_timeline%>%filter(party=='CDU')
plot_timeline_cdu<-ggplot(twitter_data_timeline_cdu,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="CDU")
twitter_data_timeline_csu<-twitter_data_timeline%>%filter(party=='CSU')
plot_timeline_csu<-ggplot(twitter_data_timeline_csu,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="CSU")
twitter_data_timeline_linke<-twitter_data_timeline%>%filter(party=='DIE LINKE')
plot_timeline_linke<-ggplot(twitter_data_timeline_linke,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Die Linke")
twitter_data_timeline_gruene<-twitter_data_timeline%>%filter(party=='GRUENE')
plot_timeline_gruene<-ggplot(twitter_data_timeline_gruene,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Grüne")
twitter_data_timeline_fdp<-twitter_data_timeline%>%filter(party=='FDP')
plot_timeline_fdp<-ggplot(twitter_data_timeline_fdp,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="FDP")
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_csu,
plot_timeline_linke,
plot_timeline_fdp)
plot_timeline_fdp<-ggplot(twitter_data_timeline_fdp,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="yellow")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="FDP")
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_csu,
plot_timeline_linke,
plot_timeline_fdp)
plot_timeline_gruene<-ggplot(twitter_data_timeline_gruene,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="green")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Grüne")
plot_timeline_linke<-ggplot(twitter_data_timeline_linke,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="darkred")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Die Linke")
plot_timeline_csu<-ggplot(twitter_data_timeline_csu,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="black")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="CSU")
plot_timeline_cdu<-ggplot(twitter_data_timeline_cdu,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="black")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="CDU")
plot_timeline_spd<-ggplot(twitter_data_timeline_spd,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="red")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="SPD")
plot_timeline_afd<-ggplot(twitter_data_timeline_afd,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="lightblue")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="AfD")
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_csu,
plot_timeline_linke,
plot_timeline_fdp)
#CSU aus Grid entfern für bessere 3x2 Darstellung, sehr geringes Tweetvolume
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_linke,
plot_timeline_fdp)
plot_timeline_afd<-ggplot(twitter_data_timeline_afd,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="blue")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="AfD")
#CSU aus Grid entfern für bessere 3x2 Darstellung, sehr geringes Tweetvolume
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_linke,
plot_timeline_fdp)
plot_timeline_linke<-ggplot(twitter_data_timeline_linke,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="ping")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Die Linke")
plot_timeline_linke<-ggplot(twitter_data_timeline_linke,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="pink")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Die Linke")
#CSU aus Grid entfern für bessere 3x2 Darstellung, sehr geringes Tweetvolume
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_linke,
plot_timeline_fdp)
geom_bar(stat="identity", fill=#FF3399)+
plot_timeline_linke<-ggplot(twitter_data_timeline_linke,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill='#FF3399')+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Die Linke")
#CSU aus Grid entfern für bessere 3x2 Darstellung, sehr geringes Tweetvolume
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_linke,
plot_timeline_fdp)
#CSU aus Grid entfern für bessere 3x2 Darstellung, sehr geringes Tweetvolume
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_linke,
plot_timeline_fdp)
plot_timeline_linke<-ggplot(twitter_data_timeline_linke,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill='#FF3399')+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Die Linke")
#CSU aus Grid entfern für bessere 3x2 Darstellung, sehr geringes Tweetvolume
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_linke,
plot_timeline_fdp)
twitter_data_timeline_afd<-twitter_data_timeline%>%filter(party=='AfD')
plot_timeline_afd<-ggplot(twitter_data_timeline_afd,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="blue")+
ylab("count of tweets")+
xlab("weeks until election")+
labs(title="AfD")
twitter_data_timeline_spd<-twitter_data_timeline%>%filter(party=='SPD')
plot_timeline_spd<-ggplot(twitter_data_timeline_spd,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="red")+
ylab("count of tweets")+
xlab("weeks until election")+
labs(title="SPD")
twitter_data_timeline_cdu<-twitter_data_timeline%>%filter(party=='CDU')
plot_timeline_cdu<-ggplot(twitter_data_timeline_cdu,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="black")+
ylab("count of tweets")+
xlab("weeks until election")+
labs(title="CDU")
twitter_data_timeline_csu<-twitter_data_timeline%>%filter(party=='CSU')
plot_timeline_csu<-ggplot(twitter_data_timeline_csu,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="black")+
ylab("count of tweets")+
xlab("weeks until election")+
labs(title="CSU")
twitter_data_timeline_linke<-twitter_data_timeline%>%filter(party=='DIE LINKE')
plot_timeline_linke<-ggplot(twitter_data_timeline_linke,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill='#FF3399')+
ylab("count of tweets")+
xlab("weeks until election")+
labs(title="Die Linke")
twitter_data_timeline_gruene<-twitter_data_timeline%>%filter(party=='GRUENE')
plot_timeline_gruene<-ggplot(twitter_data_timeline_gruene,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="green")+
ylab("count of tweets")+
xlab("weeks until election")+
labs(title="Grüne")
twitter_data_timeline_fdp<-twitter_data_timeline%>%filter(party=='FDP')
plot_timeline_fdp<-ggplot(twitter_data_timeline_fdp,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="yellow")+
ylab("count of tweets")+
xlab("weeks until election")+
labs(title="FDP")
#CSU aus Grid entfern für bessere 3x2 Darstellung, sehr geringes Tweetvolume
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_linke,
plot_timeline_fdp)
ggplot(twitter_data_timeline,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity" ,fill='#890E1C')+
ylab("count of tweets")+
xlab("weeks until election")
View(twitter_data_cleaned)
View(twitter_data_cleaned1)
twitter_data_sentiment<-read_delim("twitter data/SentimentAnalyse#1.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_david_snd<-read_delim("data/SentimentAnalyseDavidzweiterDurchlauf.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_jakob_snd<-read_delim("twitter data/SentimentAnalyse#2.csv",
";", escape_double = FALSE, trim_ws = TRUE,
locale = locale())
View(twitter_data_sentiment)
twitter_data_sentiment<-rbind(twitter_data_sentiment,twitter_data_sentiment_jakob_snd,twitter_data_sentiment_david_snd)
#temp Plot für Paper
values <-c(twitter_data_sentiment%>%filter(isMatch="1"))
#temp Plot für Paper
values <-c(twitter_data_sentiment%>%filter(isMatch=="1"))
View(values)
#temp Plot für Paper
values <-c(nrow(twitter_data_sentiment%>%filter(isMatch=="1")))
values
go <-c("matched","polarity matched","not matched")
#temp Plot für Paper
values <-c(nrow(twitter_data_sentiment%>%filter(isMatch=="1")), nrow(twitter_data_sentiment%>%filter(isMatch=="0.5")))
values
#temp Plot für Paper
values <-c(nrow(twitter_data_sentiment%>%filter(isMatch=="1")), nrow(twitter_data_sentiment%>%filter(isMatch=="0.5")), nrow(twitter_data_sentiment
%>%filter(isMatch=="0")))
values
go <-c("matched","polarity matched","not matched")
basic_plot_data<-data.frame(go,values)
basic_plot <- ggplot(basic_plot_data, aes(y = values,x =go))
basic_plot +geom_bar(stat = "identity", fill='#890E1C') + labs(x = "", y="count of tweets")
#temp Plot für Paper
values <-c(nrow(twitter_data_sentiment%>%filter(isMatch=="1")), nrow(twitter_data_sentiment%>%filter(isMatch=="0")), nrow(twitter_data_sentiment
%>%filter(isMatch=="0.5")))
go <-c("matched","polarity matched","not matched")
#temp Plot für Paper
values <-c(nrow(twitter_data_sentiment%>%filter(isMatch=="1")), nrow(twitter_data_sentiment%>%filter(isMatch=="0.5")), nrow(twitter_data_sentiment
%>%filter(isMatch=="0")))
go <-c("matched","polarity matched","not matched")
values
go <-c("matched","polarity matched","not matched")
basic_plot_data<-data.frame(go,values)
basic_plot <- ggplot(basic_plot_data, aes(y = values,x =go))
basic_plot +geom_bar(stat = "identity", fill='#890E1C') + labs(x = "", y="count of tweets")
colnames(twitter_data_sentiment_david_snd)<-c("sentimentScore","text")
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(ID))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%select(-c(X1,ID,positveSentimentScore,negativeSentimentScore))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%filter(sentimentScore != "NA")
twitter_data_sentiment_jakob_snd$isMatch<-"1"
twitter_data_sentiment_david_snd$isMatch<-"1"
twitter_data_sentiment<-rbind(twitter_data_sentiment,twitter_data_sentiment_jakob_snd,twitter_data_sentiment_david_snd)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
# Umwandeln der Scores in numeric mit "."
twitter_data_sentiment<-twitter_data_sentiment%>%filter(sentimentScore != "NA")
twitter_data_sentiment<-twitter_data_sentiment%>%filter(text != "")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment$sentimentScore<-as.numeric(as.character(twitter_data_sentiment$sentimentScore))
>>>>>>> 55cc94dd0e279e6579ba715551e2f945fb3f362d
pos.words <-  readAndflattenSentiWS("dictionarys\SentiWS\SentiWS_v1.8c_Positive.txt")
neg.words <-  readAndflattenSentiWS("dictionarys\SentiWS\SentiWS_v1.8c_Negative.txt")
pos.words <-  readAndflattenSentiWS("dictionarys/SentiWS/SentiWS_v1.8c_Positive.txt")
neg.words <-  readAndflattenSentiWS("dictionarys/SentiWS/SentiWS_v1.8c_Negative.txt")
readAndFlattenSentiWS <- function(filename) {
words = readLines(filename, encoding="UTF-8")
words <- sub("\\|[A-Z]+\t[0-9.-]+\t?", ",", words)
words <- unlist(strsplit(words, ","))
words <- tolower(words)
return(words)
}
pos.words <-  readAndFlattenSentiWS("dictionarys/SentiWS/SentiWS_v1.8c_Positive.txt")
neg.words <-  readAndFlattenSentiWS("dictionarys/SentiWS/SentiWS_v1.8c_Negative.txt")
pos.words
words<-rbind(pos.words, neg.words)
words<-cbind(pos.words, neg.words)
View(words)
words<-c(pos.words, neg.words)
pos.scores<-rep(1,15649)
neg.scores<-rep(-1,15632)
scores<-c(pos.scores,neg.scores)
require(tidyverse)
require(dplyr)
library(readr)
library(SentimentAnalysis)
sentiWSDict<-SentimentDictionaryWeighted(words,scores)
Duplicated(pos.words, nmax= 16000)
duplicated(pos.words, nmax= 16000)
pos.words<-pos.words[!duplicated(pos.words, nmax= 16000)]
neg.words<-neg.words[!duplicated(neg.words, nmax= 16000)]
pos.scores<-rep(1,15543)
neg.scores<-rep(-1,15472)
words<-c(pos.words, neg.words)
scores<-c(pos.scores,neg.scores)
sentiWSDict<-SentimentDictionaryWeighted(words,scores)
words<-words[!duplicated(words,nmax=32000)]
pos.scores<-rep(1,15503)
neg.scores<-rep(-1,15444)
scores<-c(pos.scores,neg.scores)
sentiWSDict<-SentimentDictionaryWeighted(words,scores)
words<-gsub("ä","ae",words)
words
words<-gsub("ä","ae",words)
words<-gsub("ö","oe",words)
words<-gsub("ü","ue",words)
sentiWSDict<-SentimentDictionaryWeighted(words,scores)
words
read_delim("twitter data/twitterDataBaselineWithAllDicts.csv",sep=",")
read_delim("twitter data/twitterDataBaselineWithAllDicts.csv",",")
twitterDataBaselineWithAllDicts<-read_delim("twitter data/twitterDataBaselineWithAllDicts.csv",",")
View(twitterDataBaselineWithAllDicts)
twitterDataBaselineWithAllDicts<-twitterDataBaselineWithAllDicts%>%mutate(text=cleanTweetText(text))
predScores<-predict(sentiWSDict, twitterDataBaselineWithAllDicts$text)
twitterDataBaselineWithAllDicts$SentiWS<-predScores
sentiWSDict<-SentimentDictionaryWeighted(words,scores,idf = 1)
sentiWSDict<-SentimentDictionaryWeighted(words,scores,idf = rep(1,length(words)))
predScores<-predict(sentiWSDict, twitterDataBaselineWithAllDicts$text)
twitterDataBaselineWithAllDicts$SentiWS<-predScores
senitWSDF<-data.frame(word=character(),
score=numeric(),
addWords=character(),
stringsAsFactors = FALSE)
sentiWSPositTerms<-read_delim("dictionarys/SentiWS/SentiWS_v1.8c_Positive.txt",
delim = "\t",
col_names = c("word","score","addWords"),col_types ="cdc")
View(sentiWSPositTerms)
senitWSDF<-rbind(senitWSDF,sentiWSPositTerms)
View(senitWSDF)
sentiWSPositTerms<-read_delim("dictionarys/SentiWS/SentiWS_v1.8c_Positive.txt",
delim = "\t",
col_names = c("word","score","addWords"),col_types ="cdc")
str(sentiWSPositTerms)
sentiWSNegTerms<-read_delim("dictionarys/SentiWS/SentiWS_v1.8c_Negative.txt",
delim = "\t",
col_names = c("word","score","addWords"),col_types ="cdc")
sentiWSWordlist<-rbind(sentiWSPositTerms,sentiWSNegTerms)
sentiWSWordlist$word<-gsub("\\|NN","",sentiWSWordlist$word)
View(sentiWSWordlist)
str(sentiWSWordlist)
sentiWSWordlist<-sentiWSWordlist%>%mutate(addWords = strsplit(as.character(addWords),","))%>%unnest(addWords)
View(sentiWSWordlist)
sentiWSWordlist2<-sentiWSWordlist[addWords,scores]
sentiWSWordlist2<-sentiWSWordlist[,c(addWords,scores)]
sentiWSWordlist2<-sentiWSWordlist[,c(sentiWSWordlist$addWords,sentiWSWordlist$scores)]
sentiWSWordlist2<-sentiWSWordlist[c(sentiWSWordlist$addWords,sentiWSWordlist$scores),]
sentiWSWordlist2<-sentiWSWordlist%>%select(c(addWords,scores))
sentiWSWordlist2<-sentiWSWordlist%>%select(c("addWords","scores"))
sentiWSWordlist2<-sentiWSWordlist%>%select(c("addWords","score"))
View(sentiWSWordlist2)
sentiWSWordlist2<-sentiWSWordlist2%>%filter(addWords!="")
View(sentiWSWordlist2)
sentiWSWordlist<-sentiWSWordlist%>%select(-c("addWords"))
sentiWSWordlist<-sentiWSWordlist%>%select(-c(addWords))
View(sentiWSWordlist2)
sentiWSWordlist<-sentiWSWordlist[!duplicated(sentiWSWordlist$word)]
sentiWSWordlist<-sentiWSWordlist[,!duplicated(sentiWSWordlist$word)]
sentiWSWordlist<-sentiWSWordlist[!duplicated(sentiWSWordlist$word),]
sentiWSWordlist2<-sentiWSWordlist2[!duplicated(sentiWSWordlist2$word),]
sentiWSPositTerms<-read_delim("dictionarys/SentiWS/SentiWS_v1.8c_Positive.txt",
delim = "\t",
col_names = c("word","score","addWords"),col_types ="cdc")
sentiWSNegTerms<-read_delim("dictionarys/SentiWS/SentiWS_v1.8c_Negative.txt",
delim = "\t",
col_names = c("word","score","addWords"),col_types ="cdc")
sentiWSWordlist<-rbind(sentiWSPositTerms,sentiWSNegTerms)
sentiWSWordlist$word<-gsub("\\|NN","",sentiWSWordlist$word)
sentiWSWordlist<-sentiWSWordlist%>%mutate(addWords = strsplit(as.character(addWords),","))%>%unnest(addWords)
sentiWSWordlist2<-sentiWSWordlist%>%select(c(addWords,score))
sentiWSWordlist2<-sentiWSWordlist2%>%filter(addWords!="")
sentiWSWordlist<-sentiWSWordlist%>%select(-c(addWords))
sentiWSWordlist<-sentiWSWordlist[!duplicated(sentiWSWordlist$word),]
sentiWSWordlist2<-sentiWSWordlist2[!duplicated(sentiWSWordlist2$addWords),]
View(sentiWSWordlist2)
colnames(sentiWSWordlist2)<-c("words","score")
sentiWSWordlist<-rbind(sentiWSWordlist,sentiWSWordlist2)
colnames(sentiWSWordlist2)<-c("word","score")
sentiWSWordlist<-rbind(sentiWSWordlist,sentiWSWordlist2)
sentiWSWordlist<-sentiWSWordlist[!duplicated(sentiWSWordlist$word),]
sentiWSWordlist$word<-gsub("ä","ae",sentiWSWordlist$word)
sentiWSWordlist$word<-gsub("ö","oe",sentiWSWordlist$word)
sentiWSWordlist$word<-gsub("ü","ue",sentiWSWordlist$word)
sentiWSWordlist<-sentiWSWordlist%>%mutate(word=tolower(word))
sentiWSDict<-SentimentDictionaryWeighted(sentiWSWordlist$word,sentiWSWordlist$score,idf = rep(1,length(words)))
sentiWSDict<-SentimentDictionaryWeighted(sentiWSWordlist$word,sentiWSWordlist$score,idf = rep(1,length(sentiWSWordlist$word)))
sentiWSWordlist<-sentiWSWordlist[!duplicated(sentiWSWordlist$word),]
sentiWSDict<-SentimentDictionaryWeighted(sentiWSWordlist$word,sentiWSWordlist$score,idf = rep(1,length(sentiWSWordlist$word)))
twitterDataBaselineWithAllDicts<-read_delim("twitter data/twitterDataBaselineWithAllDicts.csv",",")
twitterDataBaselineWithAllDicts<-twitterDataBaselineWithAllDicts%>%mutate(text=cleanTweetText(text))
predScores<-predict(sentiWSDict, twitterDataBaselineWithAllDicts$text)
twitterDataBaselineWithAllDicts$SentiWS<-predScores
View(twitterDataBaselineWithAllDicts)
twitterDataBaselineWithAllDicts$SentiWS<-as.numeric(unlist(predScores))
predScores<-as.numeric(unlist(predict(sentiWSDict, twitterDataBaselineWithAllDicts$text)))
twitterDataBaselineWithAllDicts$SentiWS<-predScores
twitterDataBaselineWithAllDicts<-twitterDataBaselineWithAllDicts%>%mutate(sentiWS=round(sentiWS, 3))
twitterDataBaselineWithAllDicts<-twitterDataBaselineWithAllDicts%>%mutate(sentiWS.Dictionary=round(sentiWS, 3))
twitterDataBaselineWithAllDicts$SentiWS<-as.numeric(unlist(predict(sentiWSDict, twitterDataBaselineWithAllDicts$text)))
View(twitterDataBaselineWithAllDicts)
convertToDirection(twitterDataBaselineWithAllDicts$lasso2)
write(sentiWSDict,"dictionarys/sentiWSDict.dict")
