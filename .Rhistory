twitter_data%>%select(createdAt=="2017-01-01 23:43:13").show()
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")%>%filter(text!=".*[.]{3}.*")
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")%>%filter(text!=".*[.]{3}")
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")%>%filter(text!=".*\\.{3}")
twitter_data[- grep("\\.\\.\\.", twitter_data$text)]
twitter_data[!grep("\\.\\.\\.", twitter_data$text)]
twitter_data[!grepl("\\.\\.\\.", twitter_data$text)]
twitter_data[!grepl("...", twitter_data$text, fixed = TRUE)]
twitter_data<-twitter_data[!grepl("...", twitter_data$text, fixed = TRUE)]
twitter_data<-twitter_data[-grep("...", twitter_data$text, fixed = TRUE)]
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")%>%filter(text!=".*\\.{3}")
twitter_data<-twitter_data[-grep("\\.\\.\\.", twitter_data$text)]
twitter_data<-twitter_data[- grep("\\.\\.\\.", twitter_data$text)]
twitter_data<-twitter_data[- grep("\\.\\.\\.", twitter_data$text),]
View(twitter_data)
twitter_data<-twitter_data%>%mutate(sentimentScore=NA)
twitter_data$text<-gsub(","," ",twitter_data$text)
twitter_data$text<-gsub(";"," ",twitter_data$text)
twitter_data_frac<-twitter_data%>%sample_n(1000, replace=FALSE)
twitter_data_frac<-twitter_data_frac%>%select(ID,sentimentScore,text)
write.table(twitter_data_frac, "data/Twitter_Sentiment_TrainData.csv", sep = ",")
twitter_data<-twitter_data[- grep("\\.\\.\\.", twitter_data$text),]
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")%>%filter(text!=".*\\.{3}")
twitter_data<-twitter_data[!grepl("\\.\\.\\.", twitter_data$text),]
twitter_data<-twitter_data[!grepl("\\.\\.\\.", twitter_data$text),]
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
require(tidyverse)
require(dplyr)
library(readr)
source("r scripts/cleanTweetText.R")
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")%>%filter(text!=".*\\.{3}")
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")%>%filter(text!=".*\\.{3}")
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
twitter_data<-twitter_data[!grepl("\\.\\.\\.", twitter_data$text),]
twitter_data<-twitter_data[!grepl("[\\.]{3}", twitter_data$text),]
twitter_data<-twitter_data[!grepl("[\.]{3}", twitter_data$text),]
twitter_data<-twitter_data[!grepl("[\\.]{3}", twitter_data$text),]
View(twitter_data)
twitter_data<-twitter_data[!grepl("?:[.]{3}", twitter_data$text),]
twitter_data<-twitter_data[!grepl("^[a-zA-Z]*(\.\.\.)$", twitter_data$text),]
twitter_data<-twitter_data[!grepl("^[a-zA-Z]*(\\.\\.\\.)$", twitter_data$text),]
twitter_data<-twitter_data[!grep("^[a-zA-Z]*(\\.\\.\\.)$", twitter_data$text),]
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
require(tidyverse)
require(dplyr)
library(readr)
source("r scripts/cleanTweetText.R")
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
twitter_data<-twitter_data[!grepl("^[a-zA-Z]*(\\.\\.\\.)$", twitter_data$text),]
twitter_data<-twitter_data[!grepl("\\.\\.\\.", twitter_data$text),]
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data_bin<-twitter_data[grepl("\\.\\.\\.", twitter_data$text),]
View(twitter_data_bin)
twitter_data_bin<-twitter_data[grepl("htt.{3,}",twitter_data$text),]
View(twitter_data_bin)
twitter_data_bin<-twitter_data[!grepl("htt.{3,}",twitter_data$text),]
View(twitter_data_bin)
twitter_data$text<-gsub("http[s]?.{3,}","",twitter_data$text)
View(twitter_data)
twitter_data$text<-gsub("h[t]?[t]?[p]?[.]{3}")
twitter_data$text<-gsub("h[t]?[t]?[p]?[.]{3}",twitter_data$text)
twitter_data$text<-gsub("h[t]?[t]?[p]?[.]{3}","",twitter_data$text)
View(twitter_data)
twitter_data$text<-gsub("h{1}[t]?[t]?[p]?[.]{3}","",twitter_data$text)
twitter_data_bin<-twitter_data[grepl("h{1}[t]?[t]?[p]?[.]{3}", twitter_data$text),]
View(twitter_data)
twitter_data$text<-gsub("h{1}[t]?[t]?[p]?[.]{3}","",twitter_data$text, extended = TRUE)
twitter_data_bin<-twitter_data[grep("h{1}[t]?[t]?[p]?[.]{3}", twitter_data$text),]
twitter_data$text<-gsub("h{1}[t]?[t]?[p]?\\.{3}","",twitter_data$text, extended = TRUE)
twitter_data$text<-gsub("h{1}[t]?[t]?[p]?\\.{3}","",twitter_data$text)
View(twitter_data)
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
require(tidyverse)
require(dplyr)
library(readr)
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data$text<-gsub("h{1}[t]?[t]?[p]?\\.{3}","",twitter_data$text)
View(twitter_data)
twitter_data$text<-gsub("(h{1}[t]?[t]?[p]?\\.{3})","",twitter_data$text)
View(twitter_data)
twitter_data_bin<-twitter_data[grep("h{1}[t]?[t]?[p]?[.]{3}", twitter_data$text),]
twitter_data_bin<-twitter_data[grep("(h{1}[t]?[t]?[p]?[.]{3})", twitter_data$text),]
twitter_data_bin<-twitter_data[grep("([.]{3})", twitter_data$text),]
twitter_data_bin<-twitter_data[grep("(\\t?[.]{3})", twitter_data$text),]
twitter_data$text<-gsub("(h{1}[t]?[t]?[p]?\.{3})","",twitter_data$text)
twitter_data$text<-gsub(@"(h{1}[t]?[t]?[p]?\.{3})","",twitter_data$text)
twitter_data$text<-gsub("h{1}[t]?[t]?[p]?\\.{3}","",twitter_data$text)
View(twitter_data)
twitter_data$text<-gsub("\\.{3}","",twitter_data$text)
twitter_data$text<-gsub("\\.\\.\\.","",twitter_data$text)
twitter_data_bin<-twitter_data[grep("(\U2026)", twitter_data$text),]
View(twitter_data_bin)
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
twitter_data$text<-gsub("http[s]?[^\s]*","",twitter_data$text)
twitter_data$text<-gsub("http[s]?[^\\s]*","",twitter_data$text)
View(twitter_data)
twitter_data$text<-gsub("h[t]?[t]?[p]?\U2026","",twitter_data$text)
twitter_data_bin<-twitter_data[grep("(\U2026)", twitter_data$text),]
View(twitter_data_bin)
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
twitter_data$text<-gsub("h[t]?[t]?[p]?\U2026","",twitter_data$text)
twitter_data_bin<-twitter_data[grep("(\U2026)", twitter_data$text),]
twitter_data<-twitter_data[!grep("(\U2026)", twitter_data$text),]
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
twitter_data$text<-gsub("h[t]?[t]?[p]?\U2026","",twitter_data$text)
twitter_data<-twitter_data[!grep("\U2026", twitter_data$text),]
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
twitter_data$text<-gsub("h[t]?[t]?[p]?\U2026","",twitter_data$text)
twitter_data_cleaned<-twitter_data[!grep("\U2026", twitter_data$text),]
twitter_data_cleaned<-twitter_data[!grepl("\U2026", twitter_data$text),]
View(twitter_data_cleaned)
twitter_data<-twitter_data[!grepl("\U2026", twitter_data$text),]
twitter_data<-twitter_data%>%mutate(sentimentScore=NA)
twitter_data$text<-gsub(","," ",twitter_data$text)
twitter_data$text<-gsub(";"," ",twitter_data$text)
twitter_data_frac<-twitter_data%>%sample_n(1000, replace=FALSE)
twitter_data_frac<-twitter_data_frac%>%select(ID,sentimentScore,text)
write.table(twitter_data_frac, "data/Twitter_Sentiment_TrainData.csv", sep = ",")
twitter_data_empty_tweets<-twitter_data%>%filter(text=="")
View(twitter_data_empty_tweets)
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
View(twitter_data)
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
twitter_data$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data$text)
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
twitter_data$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data$text)
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
twitter_data$text<-gsub("h[t]?[t]?[p]?\U2026","",twitter_data$text)
twitter_data<-twitter_data[!grepl("\U2026", twitter_data$text),]
twitter_data_empty_tweets<-twitter_data%>%filter(text=="")
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
twitter_data$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data$text)
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
twitter_data$text<-gsub("h[t]?[t]?[p]?\U2026","",twitter_data$text)
twitter_data_bin<-twitter_data[grepl("\U2026", twitter_data$text),]
View(twitter_data_bin)
twitter_data_bin_empty<-twitter_data_bin%>%filter(text=="")
twitter_data<-twitter_data[!grepl("\U2026", twitter_data$text),]
twitter_data<-twitter_data%>%mutate(sentimentScore=NA)
twitter_data$text<-gsub(","," ",twitter_data$text)
twitter_data$text<-gsub(";"," ",twitter_data$text)
twitter_data_frac<-twitter_data%>%sample_n(1000, replace=FALSE)
twitter_data_frac<-twitter_data_frac%>%select(ID,sentimentScore,text)
write.table(twitter_data_frac, "data/Twitter_Sentiment_TrainData.csv", sep = ",")
write.table(twitter_data_frac, "data/Twitter_Sentiment_TrainData.csv", sep = ",")
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
twitter_data$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data$text)
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
twitter_data$text<-gsub("ht[t]?[p]?\U2026","",twitter_data$text)
twitter_data<-twitter_data[!grepl("\U2026", twitter_data$text),]
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
twitter_data$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data$text)
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
twitter_data$text<-gsub("htt[p]?\U2026","",twitter_data$text)
twitter_data<-twitter_data[!grepl("\U2026", twitter_data$text),]
twitter_data_sentiment<-read_delim("data/Twitter_Sentiment_TrainData.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment<-read_delim("data/Twitter_Sentiment_TrainData.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(twitter_data_sentiment)
twitter_data_sample<-twitter_data_sample%>%mutate(text=cleanTweetText(text))
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
View(twitter_data_sentiment)
source("r scripts/cleanTweetText.R")
twitter_data_sentiment<-read_delim("data/Twitter_Sentiment_TrainData.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
View(twitter_data_sentiment)
source("r scripts/cleanTweetText.R")
twitter_data_sentiment<-read_delim("data/Twitter_Sentiment_TrainData.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
View(twitter_data_sentiment)
twitter_data_sentiment<-read_delim("data/Twitter_Sentiment_TrainData.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(twitter_data_sentiment)
dict<-generateDictionary(twitter_data_sentiment$text,twitter_data_sentiment$sentimentScore)
library(SentimentAnalysis)
install.packages("SentimentAnalysis")
library(SentimentAnalysis)
dict<-generateDictionary(twitter_data_sentiment$text,twitter_data_sentiment$sentimentScore)
text<-iconv(twitter_data_sentiment$text, from = "UTF-8", to = "ASCII")
dict<-generateDictionary(text,twitter_data_sentiment$sentimentScore)
dict<-generateDictionary(text,twitter_data_sentiment$sentimentScore, language="german", modelType = "lasso", minWordLength = 2)
text<-iconv(twitter_data_sentiment$text, from = "UTF-8", to = "ASCII", toRaw = "TRUE")
dict<-generateDictionary(text,twitter_data_sentiment$sentimentScore, language="german", modelType = "lasso", minWordLength = 2)
text<-transformIntoCorpus(twitter_data_sentiment$text)
dict<-generateDictionary(text,twitter_data_sentiment$sentimentScore, language="german", modelType = "lasso", minWordLength = 2)
str(text)
View(twitter_data_sentiment)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
text<-transformIntoCorpus(twitter_data_sentiment$text)
dict<-generateDictionary(text,twitter_data_sentiment$sentimentScore, language="german", modelType = "lasso", minWordLength = 2)
dict<-generateDictionary(text,twitter_data_sentiment$sentimentScore, language="german", modelType = "lasso", minWordLength = 2)
require(tidyverse)
require(dplyr)
library(readr)
library(SentimentAnalysis)
source("r scripts/cleanTweetText.R")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
text<-transformIntoCorpus(twitter_data_sentiment$text)
dict<-generateDictionary(text,twitter_data_sentiment$sentimentScore, language="german", modelType = "lasso", minWordLength = 2)
response<-as.numeric(as.character(twitter_data_sentiment$sentimentScore))
dict<-generateDictionary(text,twitter_data_sentiment$sentimentScore, language="german", modelType = "lasso", minWordLength = 2)
dict<-generateDictionary(text,response, language="german", modelType = "lasso", minWordLength = 2)
dict<-generateDictionary(twitter_data_sentiment$text,response, language="german", modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.9, minWordLength = 2)
dict<-generateDictionary(twitter_data_sentiment$text,response, language="german", modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.9, minWordLength = 3)
text<-c("Sehr Gut", "Gut","Okay","Schlecht","Sehr Schlecht")
response<-c(1,0.5,0,0.5,1)
dict<-generateDictionary(text,response)
dict
response<-c(1,0.5,0,-0.5,-1)
dict<-generateDictionary(text,response)
dict
write.table(twitter_data_sentiment, "data/Twitter_Sent.cv",sep=",")
write.table(twitter_data_sentiment, "data/Twitter_Sent.csv",sep=",")
twitter_data_sentiment<-read_delim("data/Twitter_Sentiment_TrainData.csv",
";", escape_double = FALSE, trim_ws = TRUE)
require(tidyverse)
require(dplyr)
library(readr)
library(SentimentAnalysis)
source("r scripts/cleanTweetText.R")
twitter_data_sentiment<-read_delim("data/Twitter_Sentiment_TrainData.csv",
";", escape_double = FALSE, trim_ws = TRUE)
write.table(twitter_data_sentiment, "data/Twitter_Sent.csv",sep=",")
View(twitter_data)
require(tidyverse)
require(dplyr)
library(readr)
library(SentimentAnalysis)
source("r scripts/cleanTweetText.R")
twitter_data_sentiment<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(twitter_data_sentiment)
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c("text"))
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(text))
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,text))
twitter_data_sentiment<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,text))
twitter_data<-merge(twitter_data,twitter_data_sentiment, by = "ID")
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data_merge<-merge(x = twitter_data, y = twitter_data_sentiment, by = "ID", all.x = TRUE)
View(twitter_data_merge)
twitter_data_sentiment<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
twitter_data_merge<-merge(x = twitter_data, y = twitter_data_sentiment, by = "text", all.x = TRUE)
nrow(twitter_data_merge%>%filter(sentimentScore != "NA"))
View(twitter_data_sentiment)
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
View(twitter_data_sentiment)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
View(twitter_data_sentiment)
twitter_data_sentiment_match<-twitter_data_sentiment%>%>filter(isMatch =="1")
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(text=cleanTweetText(text))
View(twitter_data_sentiment_match)
text<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
response
twitter_data_sentiment_match<-twitter_data_sentiment%>%mutate(sentimentScore = as.numeric(sub(",", ".", sentimentScore, fixed = TRUE)))
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(twitter_data_sentiment_match$text,response, language="german", modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.9, minWordLength = 3)
install.packages("SnowballC")
install.packages("SnowballC")
library(SnowballC)
dict<-generateDictionary(twitter_data_sentiment_match$text,response, language="german", modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.9, minWordLength = 3)
require(tidyverse)
require(dplyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
dict<-generateDictionary(twitter_data_sentiment_match$text,response, language="german", modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.9, minWordLength = 3)
dict<-generateDictionary(twitter_data_sentiment_match$text,response, language="german", modelType = "lasso", minWordLength = 3)
twitter_data_sentiment$text <- iconv(twitter_data_sentiment$text, to = "utf-8")
View(twitter_data_sentiment)
twitter_data_sentiment<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
twitter_data_sentiment$text <- iconv(twitter_data_sentiment$text, to = "utf-8")
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_match<-twitter_data_sentiment%>%mutate(sentimentScore = as.numeric(sub(",", ".", sentimentScore, fixed = TRUE)))
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = as.numeric(sub(",", ".", sentimentScore, fixed = TRUE)))
twitter_data_sentiment<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
twitter_data_sentiment$text <- iconv(twitter_data_sentiment$text, to = "utf-8")
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = as.numeric(sub(",", ".", sentimentScore, fixed = TRUE)))
View(twitter_data_sentiment_match)
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(text=cleanTweetText(text))
text<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(twitter_data_sentiment_match$text,response, language="german", modelType = "lasso", minWordLength = 3)
source("r scripts/cleanTweetText.R")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(text=cleanTweetText(text))
text<-transformIntoCorpus(twitter_data_sentiment_match$text)
source("r scripts/cleanTweetText.R")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(text=cleanTweetText(text))
source("r scripts/cleanTweetText.R")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(text=cleanTweetText(text))
text<-stri_replace_all_fixed(text,
#c("ä", "ö", "ü", "Ä", "Ö", "Ü"),
c("\U00E4","\U00F6","\U00FC","\U00C4","\U00D6","\U00DC"),
c("ae", "oe", "ue", "Ae", "Oe", "Ue"), vectorize_all = FALSE)
source("r scripts/cleanTweetText.R")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(text=cleanTweetText(text))
text<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
response
dict<-generateDictionary(twitter_data_sentiment_match$text,response, language="german", modelType = "lasso", minWordLength = 3)
dict<-generateDictionary(text,response, language="german", modelType = "lasso", minWordLength = 3)
dict<-generateDictionary(text,response)
dict
dict<-generateDictionary(text,response,modelType = lasso)
dict<-generateDictionary(text,response,modelType = "lasso")
dict
summary(dict)
install.packages("tm")
library(tm)
library(spikeslab)
require(tidyverse)
require(dplyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
dict<-generateDictionary(x,response, language = "english",
modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.9, weighting = function(x)
tm::weightTfIdf(x, normalize = FALSE), ...)
dict<-generateDictionary(x,response, language = "english",
modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.9, weighting = function(x)
tm::weightTfIdf(x, normalize = FALSE))
View(twitter_data_sentiment)
twitter_data_sentiment<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(twitter_data_sentiment)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
View(twitter_data_sentiment)
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = as.numeric(sub(",", ".", sentimentScore, fixed = TRUE)))
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(text,response)
dict<-generateDictionary(x,response)
dict<-generateDictionary(x,response, language = "german",
modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.9, weighting = function(x)
tm::weightTfIdf(x, normalize = FALSE))
dict<-generateDictionary(x,response, language = "german",
modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.9)
dict<-generateDictionary(x,response, language = "deutsch",
modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.9)
dict<-generateDictionary(x,response, language = "german",
modelType = "lasso", sparsity = 0.9)
dict<-generateDictionary(x,response, language = "german",
modelType = "lasso")
dict<-generateDictionary(x,response,
modelType = "lasso")
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.9, weighting)
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.9, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
dict<-generateDictionary(twitter_data_sentiment_match$text,response)
View(dict)
View(dict)
View(dict)
require(tidyverse)
require(dplyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
# Aufbereiten Twitter Datensatz
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
#Entfernt alle Links (http(s) und alle Zeichen bis zum nächsten Leerzeichen)
twitter_data$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data$text)
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
#Entfernt alle abgeschnittenen Links
twitter_data$text<-gsub("htt[p]?\U2026","",twitter_data$text)
#Entfernen von abgeschnittenen Tweets
c
# Aufbereiten für Random Sample
twitter_data<-twitter_data%>%mutate(sentimentScore=NA)
# NUR FÜR EXCEL!
twitter_data$text<-gsub(","," ",twitter_data$text)
twitter_data$text<-gsub(";"," ",twitter_data$text)
# Random Sample
twitter_data_frac<-twitter_data%>%sample_n(1000, replace=FALSE)
twitter_data_frac<-twitter_data_frac%>%select(ID,sentimentScore,text)
write.table(twitter_data_frac, "data/Twitter_Sentiment_TrainData.csv", sep = ",")
# Auswertung
# Einlesen
twitter_data_sentiment<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
# Spalten Säubern (ID leider verfälscht)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
# Fehlerhaft bei ä,ü,ö
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
# Säubern
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
# Nur Matches der Kreuzvalid.
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
# Umwandeln der Scores in numeric mit "."
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = as.numeric(sub(",", ".", sentimentScore, fixed = TRUE)))
# Testweise join für orginalen Text
# twitter_data_merge<-merge(x = twitter_data, y = twitter_data_sentiment, by = "text", all.x = TRUE)
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(twitter_data_sentiment_match$text,response)
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.9, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
install.packages("SentimentAnalysis")
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
dict<-generateDictionary(twitter_data_sentiment_match$text,response)
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.9, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
View(dict)
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
view(dict)
View(dict)
View(dict)
df <- data.frame(matrix(unlist(dict), nrow=132, byrow=T),stringsAsFactors=FALSE)
df <- data.frame(matrix(unlist(dict), nrow=132, byrow=T),stringsAsFactors=FALSE)
df <- ldply (dict, data.frame)
df <- ldply (dict, data.frame)
install.packages("plyr")
install.packages("plyr")
library(plyr)
require(plyr)
require(plyr)
df <- ldply (dict, data.frame)
