<<<<<<< HEAD
twitter_data<-twitter_data_cleaned<-twitter_data%>%filter(lang=="de" | lang == "da")
#Entfernt alle Links (http(s) und alle Zeichen bis zum nächsten Leerzeichen)
twitter_data$text<-twitter_data_cleaned$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_cleaned$text)
twitter_data$text<-twitter_data_cleaned$text<-gsub("http.*[^\\s]+","",twitter_data_cleaned$text)
twitter_data$text<-twitter_data_cleaned$text<-gsub("https","",twitter_data_cleaned$text)
twitter_data$text<-twitter_data_cleaned$text<-gsub("http","",twitter_data_cleaned$text)
#Entfernt alle abgeschnittenen Links
twitter_data$text<-twitter_data_cleaned$text<-gsub("htt[p]?\U2026","",twitter_data$text)
#Entfernen von abgeschnittenen Tweets
twitter_data<-twitter_data_cleaned<-twitter_data[!grepl("\U2026", twitter_data$text),]
#CleanTweetText auf den gesamten Twitter Datensatz
twitter_data<-twitter_data%>%mutate(text=cleanCorpus(text))
twitter_data$text<-gsub("<[^\\s]+>","",twitter_data$text)
twitter_data_cleaned<-twitter_data_cleaned%>%mutate(text=cleanTweetText(text))
twitter_data_cleaned$text<-gsub("[^[:graph:]]"," ",twitter_data_cleaned$text)
twitter_data_cleaned$text<-iconv(twitter_data_cleaned$text, 'UTF-8','ASCII')
twitter_data_cleaned$text<-apply(twitter_data_cleaned[,"text"],1,function(x) stemTweetText(x))
twitter_data$text<-gsub("[^[:graph:]]"," ",twitter_data$text)
=======
ggplot(twitter_data_quotes,twitter_data_replies,twitter_data_retweets+aes())
ggplot(twitter_data_quotes,twitter_data_replies,twitter_data_retweets)+aes()
pplot <-ggplot(ddf,x=group, y=mean, aes(group,mean,fill=time))
pplot <-ggplot(twitter_data_sample%>%filter(inReplyToUser!='null'),x=group, y=mean, aes(group,mean,fill=time))
pplot +
geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymax = mean + se, ymin= mean - se), position = position_dodge(width=0.7), width=0.2) +
#geom_point(stat="identity", shape=21, size=5, position=position_dodge(width=0.7), width=0.2)
geom_point(stat="identity", shape=21, size=5, position=position_dodge(width=0.7))
p <-ggplot(twitter_data_sample%>%filter(isQuote==1), aes(class))
p + geom_bar()
p <-ggplot(twitter_data_sample%>%filter(isQuote==1), aes(isRetweet))
p + geom_bar()
nrow(twitter_data_retweets)
basic <-c("Retweet","Quotes","Answer")
basic
nrow(twitter_data_retweets)
values <-c(twitter_data_retweets,twitter_data_quotes,twitter_data_replies)
values
values <-c(nrow(twitter_data_retweets),nrow(twitter_data_quotes),nrow(twitter_data_replies))
values
basic_plot_data<-data.frame(basic,values)
basic_plot <- ggplot(basic_plot_data, aes(basic,values))
basic_plot <- ggplot(basic_plot_data, aes(basic,values)) + geom_bar()
basic_plot
basic_plot <- ggplot(basic_plot_data, aes(values,basic)) + geom_bar()
basic_plot
basic_plot <- ggplot(basic_plot_data, aes(values,basic))
basic_plot +geom_bar()
basic_plot <- ggplot(basic_plot_data, aes(y = values,x =basic))
basic_plot +geom_bar()
basic_plot +geom_bar(stat = "identity")
basic_plot +geom_bar(stat = "identity") + labs(x = "")
basic_plot +geom_bar(stat = "identity") + labs(x = "", y="Count of tweets")
basic_plot +geom_bar(stat = "identity") + labs(x = "", y="count of tweets")
basic_plot +geom_bar(stat = "identity", fill='#890E1C') + labs(x = "", y="count of tweets")
View(twitter_data)
# Timeline Tweets weeksTillElection
twitter_data_timeline<-twitter_data_sample%>%select(ID, party, retweetCount, weeksTillElection)
twitter_data_timeline<-twitter_data_timeline[order(twitter_data_timeline$weeksTillElection, decreasing=TRUE),]
twitter_data_timeline<-twitter_data_timeline%>%
group_by(party, weeksTillElection)%>%
summarise(count=n(),retweetCount=sum(retweetCount))
ggplot(twitter_data_timeline,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")
ggplot(twitter_data_timeline,aes(x=weeksTillElection,y=retweetCount))+
geom_bar(stat="identity", fill='#890E1C')+
ylab("Anzahl Retweets")+
xlab("Wochen bis zur Wahl")
ggplot(twitter_data_timeline,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity" ,fill='#890E1C')+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")
ggplot(twitter_data_timeline,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity" ,fill='#890E1C')+
ylab("count of tweets")+
xlab("Weeks until election")
ggplot(twitter_data_timeline,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity" ,fill='#890E1C')+
ylab("count of tweets")+
xlab("weeks until election")
twitter_data_timeline_afd<-twitter_data_timeline%>%filter(party=='AfD')
plot_timeline_afd<-ggplot(twitter_data_timeline_afd,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="AfD")
twitter_data_timeline_spd<-twitter_data_timeline%>%filter(party=='SPD')
plot_timeline_spd<-ggplot(twitter_data_timeline_spd,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="SPD")
twitter_data_timeline_cdu<-twitter_data_timeline%>%filter(party=='CDU')
plot_timeline_cdu<-ggplot(twitter_data_timeline_cdu,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="CDU")
twitter_data_timeline_csu<-twitter_data_timeline%>%filter(party=='CSU')
plot_timeline_csu<-ggplot(twitter_data_timeline_csu,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="CSU")
twitter_data_timeline_linke<-twitter_data_timeline%>%filter(party=='DIE LINKE')
plot_timeline_linke<-ggplot(twitter_data_timeline_linke,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Die Linke")
twitter_data_timeline_gruene<-twitter_data_timeline%>%filter(party=='GRUENE')
plot_timeline_gruene<-ggplot(twitter_data_timeline_gruene,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Grüne")
twitter_data_timeline_fdp<-twitter_data_timeline%>%filter(party=='FDP')
plot_timeline_fdp<-ggplot(twitter_data_timeline_fdp,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="FDP")
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_csu,
plot_timeline_linke,
plot_timeline_fdp)
plot_timeline_fdp<-ggplot(twitter_data_timeline_fdp,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="yellow")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="FDP")
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_csu,
plot_timeline_linke,
plot_timeline_fdp)
plot_timeline_gruene<-ggplot(twitter_data_timeline_gruene,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="green")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Grüne")
plot_timeline_linke<-ggplot(twitter_data_timeline_linke,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="darkred")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Die Linke")
plot_timeline_csu<-ggplot(twitter_data_timeline_csu,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="black")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="CSU")
plot_timeline_cdu<-ggplot(twitter_data_timeline_cdu,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="black")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="CDU")
plot_timeline_spd<-ggplot(twitter_data_timeline_spd,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="red")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="SPD")
plot_timeline_afd<-ggplot(twitter_data_timeline_afd,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="lightblue")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="AfD")
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_csu,
plot_timeline_linke,
plot_timeline_fdp)
#CSU aus Grid entfern für bessere 3x2 Darstellung, sehr geringes Tweetvolume
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_linke,
plot_timeline_fdp)
plot_timeline_afd<-ggplot(twitter_data_timeline_afd,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="blue")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="AfD")
#CSU aus Grid entfern für bessere 3x2 Darstellung, sehr geringes Tweetvolume
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_linke,
plot_timeline_fdp)
plot_timeline_linke<-ggplot(twitter_data_timeline_linke,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="ping")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Die Linke")
plot_timeline_linke<-ggplot(twitter_data_timeline_linke,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="pink")+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Die Linke")
#CSU aus Grid entfern für bessere 3x2 Darstellung, sehr geringes Tweetvolume
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_linke,
plot_timeline_fdp)
geom_bar(stat="identity", fill=#FF3399)+
plot_timeline_linke<-ggplot(twitter_data_timeline_linke,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill='#FF3399')+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Die Linke")
#CSU aus Grid entfern für bessere 3x2 Darstellung, sehr geringes Tweetvolume
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_linke,
plot_timeline_fdp)
#CSU aus Grid entfern für bessere 3x2 Darstellung, sehr geringes Tweetvolume
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_linke,
plot_timeline_fdp)
plot_timeline_linke<-ggplot(twitter_data_timeline_linke,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill='#FF3399')+
ylab("Anzahl Tweets")+
xlab("Wochen bis zur Wahl")+
labs(title="Die Linke")
#CSU aus Grid entfern für bessere 3x2 Darstellung, sehr geringes Tweetvolume
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_linke,
plot_timeline_fdp)
twitter_data_timeline_afd<-twitter_data_timeline%>%filter(party=='AfD')
plot_timeline_afd<-ggplot(twitter_data_timeline_afd,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="blue")+
ylab("count of tweets")+
xlab("weeks until election")+
labs(title="AfD")
twitter_data_timeline_spd<-twitter_data_timeline%>%filter(party=='SPD')
plot_timeline_spd<-ggplot(twitter_data_timeline_spd,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="red")+
ylab("count of tweets")+
xlab("weeks until election")+
labs(title="SPD")
twitter_data_timeline_cdu<-twitter_data_timeline%>%filter(party=='CDU')
plot_timeline_cdu<-ggplot(twitter_data_timeline_cdu,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="black")+
ylab("count of tweets")+
xlab("weeks until election")+
labs(title="CDU")
twitter_data_timeline_csu<-twitter_data_timeline%>%filter(party=='CSU')
plot_timeline_csu<-ggplot(twitter_data_timeline_csu,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="black")+
ylab("count of tweets")+
xlab("weeks until election")+
labs(title="CSU")
twitter_data_timeline_linke<-twitter_data_timeline%>%filter(party=='DIE LINKE')
plot_timeline_linke<-ggplot(twitter_data_timeline_linke,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill='#FF3399')+
ylab("count of tweets")+
xlab("weeks until election")+
labs(title="Die Linke")
twitter_data_timeline_gruene<-twitter_data_timeline%>%filter(party=='GRUENE')
plot_timeline_gruene<-ggplot(twitter_data_timeline_gruene,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="green")+
ylab("count of tweets")+
xlab("weeks until election")+
labs(title="Grüne")
twitter_data_timeline_fdp<-twitter_data_timeline%>%filter(party=='FDP')
plot_timeline_fdp<-ggplot(twitter_data_timeline_fdp,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity", fill="yellow")+
ylab("count of tweets")+
xlab("weeks until election")+
labs(title="FDP")
#CSU aus Grid entfern für bessere 3x2 Darstellung, sehr geringes Tweetvolume
grid.arrange(plot_timeline_afd,
plot_timeline_gruene,
plot_timeline_spd,
plot_timeline_cdu,
plot_timeline_linke,
plot_timeline_fdp)
ggplot(twitter_data_timeline,aes(x=weeksTillElection,y=count))+
geom_bar(stat="identity" ,fill='#890E1C')+
ylab("count of tweets")+
xlab("weeks until election")
>>>>>>> d271a4e3c3d377a1669a075c85075c72c01bc592
View(twitter_data_cleaned)
twitter_data2<-read_csv("twitter data/twitter_data.csv",
locale = locale())
twitter_data22<-transformIntoCorpus(twitter_data2)
twitter_data22<-transformIntoCorpus(twitter_data2$text)
twitter_data22<-preprocessCorpus(twitter_data22,language = "german",stemming = FALSE, removeStopwords = TRUE)
twitter_data_sentiment<-read_delim("twitter data/SentimentAnalyse#1.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_david_snd<-read_delim("data/SentimentAnalyseDavidzweiterDurchlauf.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_jakob_snd<-read_delim("twitter data/SentimentAnalyse#2.csv",
";", escape_double = FALSE, trim_ws = TRUE,
locale = locale())
colnames(twitter_data_sentiment_david_snd)<-c("sentimentScore","text")
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(ID))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%select(-c(X1,ID,positveSentimentScore,negativeSentimentScore))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%filter(sentimentScore != "NA")
twitter_data_sentiment_jakob_snd$isMatch<-"1"
twitter_data_sentiment_david_snd$isMatch<-"1"
twitter_data_sentiment<-rbind(twitter_data_sentiment,twitter_data_sentiment_jakob_snd,twitter_data_sentiment_david_snd)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
# Umwandeln der Scores in numeric mit "."
twitter_data_sentiment<-twitter_data_sentiment%>%filter(sentimentScore != "NA")
twitter_data_sentiment<-twitter_data_sentiment%>%filter(text != "")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment$sentimentScore<-as.numeric(as.character(twitter_data_sentiment$sentimentScore))
<<<<<<< HEAD
# Stemming
twitter_data_sentiment$text<-apply(twitter_data_sentiment[,"text"],1,function(x) stemTweetText(x))
###
# Cleaning Functions Changed often for different Cleaning approaches of different Imported Data
###
cleanTweetText<-function(text){
require(stringr)
require(stringi)
library(tm)
library(SnowballC)
hashtag_pattern <- "#([[:alnum:]]|[_])+"
mention_pattern <- "@([[:alnum:]]|[_])+"
strip_RT_pattern<-"RT\\s@([[:alnum:]]|[_])+:"
text<-gsub("<e4>","ae",text)
text<-gsub("<c4>","Ae",text)
text<-gsub("<d6>","Oe",text)
text<-gsub("<dc>","UE",text)
text<-gsub("<f6>","oe",text)
text<-gsub("<fc>","ue",text)
text<-gsub("<df>","ss",text)
text<-gsub("ß","ss",text)
text<-gsub("\U00DF","ss",text)
text<-gsub("\U00E3","ae",text)
text<-gsub("<[^\\s]+>","",text)
text<-gsub("<[^\\s]+","",text)
text<-gsub("&amp;"," ",text)
text<-gsub("&amp"," ",text)
text<-gsub(" amp "," ",text)
text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",text)
text<-gsub("http.*[^\\s]+","",text)
text<-gsub("htt[p]?\U2026","",text)
text<-gsub("https","",text)
text<-gsub("http","",text)
text<-ifelse(grepl("\U2026",text),"",text)
#Die URLs und Mentions werden entfernt
text<-str_replace_all(text,pattern=mention_pattern,replacement="")
#Wörter die weniger als 3 Zeichen haben müssen weg außer sie haben #
text<-str_replace_all(text,pattern="(?<!#)\\b[a-zA-Z0-9]{1,2}\\b",replacement = "")
#depends on whether you wanna keep hashtags or not
text<-str_replace_all(text,pattern="#",replacement="")
#Konvertierung von Umlauten
text<-stri_replace_all_fixed(text,
#c("?", "?", "?", "?", "?", "?"),
c("\U00E4","\U00F6","\U00FC","\U00C4","\U00D6","\U00DC"),
c("ae", "oe", "ue", "Ae", "Oe", "Ue"), vectorize_all = FALSE)
#Zahlen außer IN Hashtags
text<-str_replace_all(text,pattern="\\b\\d+\\b",replacement="")
#Satzzeichen und Special Characters außer # müssen weg
text<-str_replace_all(text,pattern="[^[:alnum:]#]",replacement=" ")
text<-str_to_lower(text)
text<-gsub("\\s+", " ",text)
text<-sub("\\s+$", "", text)
#text<-substr(text, 1, 30)
return(text)
}
cleanTweetText("gute amp richtige entscheidung")
stemTweetText<-function(text){
require(stringr)
require(stringi)
library(tm)
library(SnowballC)
text<-as.character(text)
text<-strsplit(text," ")
words<-unlist(text)
words<-words[words!=""]
words<-wordStem(words,language="german")
words<-paste(words,collapse=" ")
return(words)
}
cleanCorpus<-function(text){
require(stringr)
require(stringi)
text<-gsub("<e4>","ä",text)
text<-gsub("<c4>","Ä",text)
text<-gsub("<d6>","Ö",text)
text<-gsub("<dc>","Ü",text)
text<-gsub("<f6>","ö",text)
text<-gsub("<fc>","ü",text)
text<-gsub("<df>","ss",text)
text<-gsub("ß","ss",text)
text<-gsub("<[^\\s]+>","",text)
text<-gsub("<[^\\s]+","",text)
text<-gsub("\U00E3","ä",text)
text<-gsub("&amp;"," ",text)
text<-gsub("&amp"," ",text)
text<-gsub(" amp "," ",text)
text<-stri_replace_all_fixed(text,
#c("?", "?", "?", "?", "?", "?"),
c("\U00E4","\U00F6","\U00FC","\U00C4","\U00D6","\U00DC"),
c("ae", "oe", "ue", "Ae", "Oe", "Ue"), vectorize_all = FALSE)
text<-str_replace_all(text,pattern="[^[:alnum:]\\#|\\@]",replacement=" ")
text<-gsub("\\s+", " ",text)
return(text)
}
cleanTextForMerge<-function(text){
mention_pattern <- "@([[:alnum:]]|[_])+"
text<-gsub("<e4>","ae",text)
text<-gsub("<c4>","Ae",text)
text<-gsub("<d6>","Oe",text)
text<-gsub("<dc>","UE",text)
text<-gsub("<f6>","oe",text)
text<-gsub("<fc>","ue",text)
text<-gsub("<df>","ss",text)
text<-gsub("ß","ss",text)
text<-gsub("\U00DF","ss",text)
text<-gsub("\U00E3","ae",text)
text<-gsub("<[^\\s]+>","",text)
text<-gsub("<[^\\s]+","",text)
text<-gsub("&amp;"," ",text)
text<-gsub("&amp"," ",text)
text<-gsub(" amp "," ",text)
text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",text)
text<-gsub("http.*[^\\s]+","",text)
text<-gsub("htt[p]?\U2026","",text)
text<-gsub("https","",text)
text<-gsub("http","",text)
text<-gsub("\U2026","",text)
#Die URLs und Mentions werden entfernt
text<-str_replace_all(text,pattern=mention_pattern,replacement="")
#Wörter die weniger als 3 Zeichen haben müssen weg außer sie haben #
text<-str_replace_all(text,pattern="(?<!#)\\b[a-zA-Z0-9]{1,2}\\b",replacement = "")
#depends on whether you wanna keep hashtags or not
text<-str_replace_all(text,pattern="#",replacement="")
#Konvertierung von Umlauten
text<-stri_replace_all_fixed(text,
#c("?", "?", "?", "?", "?", "?"),
c("\U00E4","\U00F6","\U00FC","\U00C4","\U00D6","\U00DC"),
c("ae", "oe", "ue", "Ae", "Oe", "Ue"), vectorize_all = FALSE)
#Zahlen außer IN Hashtags
text<-str_replace_all(text,pattern="\\b\\d+\\b",replacement="")
#Satzzeichen und Special Characters außer # müssen weg
text<-str_replace_all(text,pattern="[^[:alnum:]#]",replacement=" ")
text<-str_to_lower(text)
text<-gsub("\\s+", " ",text)
text<-sub("\\s+$", "", text)
#text<-substr(text, 1, 30)
return(text)
}
=======
require(tidyverse)
require(dplyr)
require(plyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
setwd("C:/Users/David/Downloads/Uni/CSS/projekt/CSS-WS17-18-master")
dict_ridge-2level <-read("dictionarys/ridge-2leve.dict")
dict_ridge-2level <-read("dictionarys\ridge-2level.dict")
dict_ridge_2level <-read("dictionarys\ridge-2level.dict")
dict_ridge_2level <-read("dictionarys/ridge-2level.dict")
summary(dict_ridge_2level)
dict_ridge_3level <-read("dictionarys/ridge-3level.dict")
dict_ridge_5level <-read("dictionarys/ridge-5level.dict")
compareDictionaries(dict_ridge_level3,dict_ridge_level5)
compareDictionaries(dict_ridge_2level,dict_ridge_3level)
compareDictionaries(dict_ridge_2level,dict_ridge_3level)
compareDictionaries(dict_ridge_2level,dict_ridge_5level)
compareDictionaries(dict_ridge_2level,dict_ridge_3level)
compareDictionaries(dict_ridge_3level, dict_ridge_5level)
summary(dict_ridge_2level)
summary(dict_ridge_3level)
summary(dict_ridge_5level)
compareDictionaries(dict_ridge_2level,dict_ridge_3level)
compareDictionaries(dict_ridge_3level,dict_ridge_2level)
compareDictionaries(dict_ridge_2level,dict_ridge_5level)
compareDictionaries(dict_ridge_3level, dict_ridge_5level)
dict_lasso_2level <-read("dictionarys/lasso-2level.dict")
dict_lasso_3level <-read("dictionarys/lasso-3level.dict")
dict_lasso_5level <-read("dictionarys/lasso-5level.dict")
summary(dict_lasso_5level)
summary(dict_lasso_2level)
summary(dict_lasso_3level)
summary(dict_lasso_2level)
summary(dict_lasso_3level)
summary(dict_lasso_5level)
compareDictionaries(dict_lasso_2level,dict_lasso_5level)
compareDictionaries(dict_lasso_3level,dict_lasso_2level)
compareDictionaries(dict_lasso_3level,dict_lasso_5level)
dict_enet_2level <-read("dictionarys/enet-2level.dict")
dict_enet_3level <-read("dictionarys/enet-3level.dict")
dict_enet_5level <-read("dictionarys/enet-5level.dict")
summary(dict_enet_2level)
summary(dict_enet_3level)
summary(dict_enet_5level)
>>>>>>> d271a4e3c3d377a1669a075c85075c72c01bc592
twitter_data_sentiment<-read_delim("twitter data/SentimentAnalyse#1.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_david_snd<-read_delim("data/SentimentAnalyseDavidzweiterDurchlauf.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_jakob_snd<-read_delim("twitter data/SentimentAnalyse#2.csv",
";", escape_double = FALSE, trim_ws = TRUE,
locale = locale())
colnames(twitter_data_sentiment_david_snd)<-c("sentimentScore","text")
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(ID))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%select(-c(X1,ID,positveSentimentScore,negativeSentimentScore))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%filter(sentimentScore != "NA")
twitter_data_sentiment_jakob_snd$isMatch<-"1"
twitter_data_sentiment_david_snd$isMatch<-"1"
<<<<<<< HEAD
=======
#temp Plot für Paper
values <-c(nrow(twitter_data_sentiment%>%filter(isMatch=="1")), nrow(twitter_data_sentiment%>%filter(isMatch=="0.5")), nrow(twitter_data_sentiment
%>%filter(isMatch=="0")))
>>>>>>> d271a4e3c3d377a1669a075c85075c72c01bc592
twitter_data_sentiment<-rbind(twitter_data_sentiment,twitter_data_sentiment_jakob_snd,twitter_data_sentiment_david_snd)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
# Umwandeln der Scores in numeric mit "."
twitter_data_sentiment<-twitter_data_sentiment%>%filter(sentimentScore != "NA")
twitter_data_sentiment<-twitter_data_sentiment%>%filter(text != "")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment$sentimentScore<-as.numeric(as.character(twitter_data_sentiment$sentimentScore))
<<<<<<< HEAD
View(twitter_data_sentiment)
twitter_data_sentiment$text<-apply(twitter_data_sentiment[,"text"],1,function(x) stemTweetText(x))
View(twitter_data_sentiment)
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data<-read_csv("twitter data/twitter_data.csv",
locale = locale())
# Aufbereiten Twitter Datensatz
twitter_data<-twitter_data_cleaned<-twitter_data%>%filter(lang=="de" | lang == "da")
#Entfernt alle Links (http(s) und alle Zeichen bis zum nächsten Leerzeichen)
twitter_data$text<-twitter_data_cleaned$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_cleaned$text)
twitter_data$text<-twitter_data_cleaned$text<-gsub("http.*[^\\s]+","",twitter_data_cleaned$text)
twitter_data$text<-twitter_data_cleaned$text<-gsub("https","",twitter_data_cleaned$text)
twitter_data$text<-twitter_data_cleaned$text<-gsub("http","",twitter_data_cleaned$text)
twitter_data$text<-twitter_data_cleaned$text<-gsub("htt[p]?\U2026","",twitter_data$text)
twitter_data<-twitter_data_cleaned<-twitter_data[!grepl("\U2026", twitter_data$text),]
twitter_data<-twitter_data%>%mutate(text=cleanCorpus(text))
twitter_data$text<-gsub("<[^\\s]+>","",twitter_data$text)
twitter_data_cleaned<-twitter_data_cleaned%>%mutate(text=cleanTweetText(text))
twitter_data<-twitter_data%>%mutate(text=cleanCorpus(text))
View(twitter_data_cleaned)
twitter_data_cleaned<-twitter_data_cleaned%>%mutate(text=cleanTweetText(text))
View(twitter_data_cleaned)
View(twitter_data_cleaned)
twitter_data_cleaned$text<-gsub("[^[:graph:]]"," ",twitter_data_cleaned$text)
twitter_data_cleaned$text<-iconv(twitter_data_cleaned$text, 'UTF-8','ASCII')
twitter_data$text<-gsub("[^[:graph:]]"," ",twitter_data$text)
View(twitter_data_cleaned)
twitter_data_cleaned$text<-apply(twitter_data_cleaned[,"text"],1,function(x) stemTweetText(x))
gr<-grepl("",twitter_data_cleaned$text)
gr
gr<-grepl(NA,twitter_data_cleaned$text)
gr
gr<-twitter_data_cleaned$text!=""
gr
gr<-twitter_data_cleaned$text!="NA"
twitter_data_cleaned[224,1]
gr<-twitter_data_cleaned$text!=NA
gr
gr<-twitter_data_cleaned$text!="NA"
gr
twitter_data2<-twitter_data[gr,]
twitter_data<-twitter_data[gr,]
twitter_data_cleaned<-twitter_data_cleaned[gr,]
twitter_data_sentiment<-read_delim("twitter data/SentimentAnalyse#1.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_david_snd<-read_delim("data/SentimentAnalyseDavidzweiterDurchlauf.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_jakob_snd<-read_delim("twitter data/SentimentAnalyse#2.csv",
";", escape_double = FALSE, trim_ws = TRUE,
locale = locale())
colnames(twitter_data_sentiment_david_snd)<-c("sentimentScore","text")
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(ID))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%select(-c(X1,ID,positveSentimentScore,negativeSentimentScore))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%filter(sentimentScore != "NA")
twitter_data_sentiment_jakob_snd$isMatch<-"1"
twitter_data_sentiment_david_snd$isMatch<-"1"
twitter_data_sentiment<-rbind(twitter_data_sentiment,twitter_data_sentiment_jakob_snd,twitter_data_sentiment_david_snd)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
View(twitter_data_sentiment)
# Umwandeln der Scores in numeric mit "."
twitter_data_sentiment<-twitter_data_sentiment%>%filter(sentimentScore != "NA")
twitter_data_sentiment<-twitter_data_sentiment%>%filter(text != "")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment$sentimentScore<-as.numeric(as.character(twitter_data_sentiment$sentimentScore))
# Stemming
twitter_data_sentiment$text<-apply(twitter_data_sentiment[,"text"],1,function(x) stemTweetText(x))
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_5lvl<-twitter_data_sentiment_match
twitter_data_sentiment_5lvl<-twitter_data_sentiment_5lvl%>%select("sentimentScore", "text")
write.csv(twitter_data_sentiment_5lvl, "data/SentimentAnalyse_5LevelDict.csv")
=======
# Stemming
twitter_data_sentiment$text<-apply(twitter_data_sentiment[,"text"],1,function(x) stemTweetText(x))
# Nur Matches der Kreuzvalid.
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_5lvl<-twitter_data_sentiment_match
twitter_data_sentiment_5lvl<-twitter_data_sentiment_5lvl%>%select("sentimentScore", "text")
>>>>>>> d271a4e3c3d377a1669a075c85075c72c01bc592
response5<-twitter_data_sentiment_5lvl$sentimentScore
x5<-transformIntoCorpus(twitter_data_sentiment_5lvl$text)
xDTM5<-toDocumentTermMatrix(x5, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE)
<<<<<<< HEAD
dict_lasso51<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
summary(dict_lasso51)
dict_lasso52<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso53<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso54<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
summary(dict_lasso52)
summary(dict_lasso53)
summary(dict_lasso54)
dict_lasso55<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso56<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso57<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso58<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso59<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso510<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso5<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
summary(dict_lasso55)
summary(dict_lasso56)
summary(dict_lasso57)
summary(dict_lasso58)
summary(dict_lasso59)
summary(dict_lasso5)
dict_lasso52<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso53<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso54<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso55<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso56<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso57<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso58<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso59<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso510<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lasso5<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
summary(dict_lasso5)
summary(dict_lasso52)
summary(dict_lasso53)
summary(dict_lasso54)
summary(dict_lasso55)
summary(dict_lasso56)
summary(dict_lasso57)
summary(dict_lasso58)
summary(dict_lasso59)
summary(dict_lasso510)
write(dict_lasso56, "dictionarys/lasso-5level.dict")
dict_enet51<-generateDictionary(xDTM5,response5,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet52<-generateDictionary(xDTM5,response5,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet53<-generateDictionary(xDTM5,response5,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet54<-generateDictionary(xDTM5,response5,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet55<-generateDictionary(xDTM5,response5,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet56<-generateDictionary(xDTM5,response5,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet57<-generateDictionary(xDTM5,response5,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet58<-generateDictionary(xDTM5,response5,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet59<-generateDictionary(xDTM5,response5,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet510<-generateDictionary(xDTM5,response5,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
summary(dict_enet51)
summary(dict_enet52)
summary(dict_enet53)
summary(dict_enet54)
summary(dict_enet55)
summary(dict_enet56)
summary(dict_enet57)
summary(dict_enet58)
summary(dict_enet59)
summary(dict_enet510)
dict_enet52
summary(dict_enet52)
write(dict_enet52, "dictionarys/enet-5level.dict")
dict_ridge5<-generateDictionary(xDTM5,response5,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
summary(dict_ridge5)
plot(dict_ridge5)
write(dict_ridge5, "dictionarys/ridge-5level.dict")
ridge_5lvl<-read("dictionarys/ridge-5level.dict")
twitter_data1<-twitter_data[1:120000,]
twitter_data2<-twitter_data[120001:255307,]
twitter_data_cleaned1<-twitter_data_cleaned[1:120000,]
twitter_data_cleaned2<-twitter_data_cleaned[120001:255307,]
library(readr)
twitterDataBaselineWithAllDicts <- read_csv("D:/GitHub/CSS-WS17-18/twitter data/twitterDataBaselineWithAllDicts.csv",
locale = locale())
View(twitterDataBaselineWithAllDicts)
twitterDataBaselineWithAllDicts<-twitterDataBaselineWithAllDicts%>%mutate(text=cleanTweetText(text))
twitterDataBaselineWithAllDicts<-twitterDataBaselineWithAllDicts%>%mutate(text=cleanTweetText(text))
pred<-predict(ridge_5lvl,twitterDataBaselineWithAllDicts$text)
twitterDataBaselineWithAllDicts$ridge5NEW<-as.numeric(unlist(pred))
compareToResponse(pred,twitterDataBaselineWithAllDicts$sentimentScore)
compareToResponse(pred,as.numeric(twitterDataBaselineWithAllDicts$sentimentScore))
write(dict_ridge5, "dictionarys/ridge-5level.dict")
twitter_data_sentiment_3lvl<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub("0.5","1.0", sentimentScore, fixed = TRUE))
twitter_data_sentiment_3lvl<-twitter_data_sentiment_3lvl%>%select("sentimentScore", "text")
twitter_data_sentiment_3lvl$sentimentScore<-as.numeric(as.character(twitter_data_sentiment_3lvl$sentimentScore))
write.csv(twitter_data_sentiment_3lvl, "data/SentimentAnalyse_3LevelDict")
x3<-transformIntoCorpus(twitter_data_sentiment_3lvl$text)
xDTM3<-toDocumentTermMatrix(x3, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE)
response3<-twitter_data_sentiment_3lvl$sentimentScore
dict_lasso31<-generateDictionary(xDTM3,response3,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso32<-generateDictionary(xDTM3,response3,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso33<-generateDictionary(xDTM3,response3,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso34<-generateDictionary(xDTM3,response3,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso35<-generateDictionary(xDTM3,response3,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso36<-generateDictionary(xDTM3,response3,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso37<-generateDictionary(xDTM3,response3,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso38<-generateDictionary(xDTM3,response3,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso39<-generateDictionary(xDTM3,response3,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso310<-generateDictionary(xDTM3,response3,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
summary(dict_lasso31)
summary(dict_lasso32)
summary(dict_lasso33)
summary(dict_lasso34)
summary(dict_lasso35)
summary(dict_lasso36)
summary(dict_lasso37)
summary(dict_lasso38)
summary(dict_lasso39)
summary(dict_lasso310)
View(twitter_data_sentiment_3lvl)
write(dict_lasso38, "dictionarys/lasso-3level.dict")
dict_lasso38
dict_enet31<-generateDictionary(xDTM3,response3,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet32<-generateDictionary(xDTM3,response3,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet33<-generateDictionary(xDTM3,response3,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet34<-generateDictionary(xDTM3,response3,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet35<-generateDictionary(xDTM3,response3,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet36<-generateDictionary(xDTM3,response3,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet37<-generateDictionary(xDTM3,response3,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet38<-generateDictionary(xDTM3,response3,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet39<-generateDictionary(xDTM3,response3,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet310<-generateDictionary(xDTM3,response3,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
summary(dict_enet31)
summary(dict_enet32)
summary(dict_enet33)
summary(dict_enet34)
summary(dict_enet35)
summary(dict_enet36)
summary(dict_enet37)
summary(dict_enet38)
summary(dict_enet39)
summary(dict_enet310)
write(dict_enet35, "dictionarys/enet-3level.dict")
dict_enet35
summary(dict_enet35)
write(dict_enet35, "dictionarys/enet-3level.dict")
dict_ridge3<-generateDictionary(xDTM3,response3,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
compareToResponse(predict(dict_lasso5,twitterDataBaselineWithAllDicts$text),as.numeric(twitterDataBaselineWithAllDicts$sentimentScore))
summary(dict_lasso5)
lasso_5lvl<-read("dictionarys/lasso-5level.dict")
compareToResponse(predict(lasso_5,twitterDataBaselineWithAllDicts$text),as.numeric(twitterDataBaselineWithAllDicts$sentimentScore))
compareToResponse(predict(lasso_5lvl,twitterDataBaselineWithAllDicts$text),as.numeric(twitterDataBaselineWithAllDicts$sentimentScore))
twitterDataBaselineWithAllDicts$lasso5NEW<-as.numeric(unlist(predict(lasso_5lvl,twitterDataBaselineWithAllDicts$text)))
twitterDataBaselineWithAllDicts<-twitterDataBaselineWithAllDicts%>%mutate(text=stemTweetText(text))
compareToResponse(predict(lasso_5lvl,twitterDataBaselineWithAllDicts$text),as.numeric(twitterDataBaselineWithAllDicts$sentimentScore))
twitterDataBaselineWithAllDicts$text<-apply(twitterDataBaselineWithAllDicts[,"text"],1,function(x) stemTweetText(x))
library(readr)
twitterDataBaselineWithAllDicts <- read_csv("D:/GitHub/CSS-WS17-18/twitter data/twitterDataBaselineWithAllDicts.csv",
locale = locale())
View(twitterDataBaselineWithAllDicts)
twitterDataBaselineWithAllDicts<-twitterDataBaselineWithAllDicts%>%mutate(text=cleanTweetText(text))
twitterDataBaselineWithAllDicts<-twitterDataBaselineWithAllDicts%>%mutate(text=cleanTweetText(text))
twitterDataBaselineWithAllDicts$text<-apply(twitterDataBaselineWithAllDicts[,"text"],1,function(x) stemTweetText(x))
compareToResponse(predict(lasso_5lvl,twitterDataBaselineWithAllDicts$text),as.numeric(twitterDataBaselineWithAllDicts$sentimentScore))
lasso_3lvl<-read("dictionarys/lasso-3level.dict")
compareToResponse(predict(lasso_3lvl,twitterDataBaselineWithAllDicts$text),as.numeric(twitterDataBaselineWithAllDicts$sentimentScore))
View(twitterDataBaselineWithAllDicts)
as.numeric(twitterDataBaselineWithAllDicts$sentimentScore)
twitterDataBaselineWithAllDicts<-twitterDataBaselineWithAllDicts%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitterDataBaselineWithAllDicts$sentimentScore<-as.numeric(as.character(twitterDataBaselineWithAllDicts$sentimentScore))
compareToResponse(predict(lasso_3lvl,twitterDataBaselineWithAllDicts$text),as.numeric(twitterDataBaselineWithAllDicts$sentimentScore))
compareToResponse(predict(lasso_5lvl,twitterDataBaselineWithAllDicts$text),as.numeric(twitterDataBaselineWithAllDicts$sentimentScore))
compareToResponse(predict(ridge_5lvl,twitterDataBaselineWithAllDicts$text),as.numeric(twitterDataBaselineWithAllDicts$sentimentScore))
compareToResponse(predict(enet_5lvl,twitterDataBaselineWithAllDicts$text),as.numeric(twitterDataBaselineWithAllDicts$sentimentScore))
summary(dict_ridge3)
write(dict_ridge3, "dictionarys/ridge-3level.dict")
twitter_data_sentiment_2lvl<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub("0.5","1", sentimentScore, fixed = TRUE))
twitter_data_sentiment_2lvl<-twitter_data_sentiment_2lvl%>%filter(sentimentScore != 0)
twitter_data_sentiment_2lvl<-twitter_data_sentiment_2lvl%>%select("sentimentScore", "text")
twitter_data_sentiment_2lvl$sentimentScore<-as.numeric(as.character(twitter_data_sentiment_2lvl$sentimentScore))
write.csv(twitter_data_sentiment_2lvl, "data/SentimentAnalyse_2LevelDict")
x2<-transformIntoCorpus(twitter_data_sentiment_2lvl$text)
xDTM2<-toDocumentTermMatrix(x2, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE)
response2<-twitter_data_sentiment_2lvl$sentimentScore
dict_lasso21<-generateDictionary(xDTM2,response2,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso22<-generateDictionary(xDTM2,response2,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso23<-generateDictionary(xDTM2,response2,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso24<-generateDictionary(xDTM2,response2,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso25<-generateDictionary(xDTM2,response2,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso26<-generateDictionary(xDTM2,response2,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso27<-generateDictionary(xDTM2,response2,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso28<-generateDictionary(xDTM2,response2,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso29<-generateDictionary(xDTM2,response2,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_lasso210<-generateDictionary(xDTM2,response2,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
summary(dict_lasso21)
summary(dict_lasso22)
summary(dict_lasso23)
summary(dict_lasso24)
summary(dict_lasso25)
summary(dict_lasso26)
summary(dict_lasso27)
summary(dict_lasso28)
summary(dict_lasso29)
summary(dict_lasso210)
write(dict_lasso27, "dictionarys/lasso-2level.dict")
summary(dict_lasso27)
dict_enet21<-generateDictionary(xDTM2,response2,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet22<-generateDictionary(xDTM2,response2,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet23<-generateDictionary(xDTM2,response2,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet24<-generateDictionary(xDTM2,response2,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet25<-generateDictionary(xDTM2,response2,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet26<-generateDictionary(xDTM2,response2,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet27<-generateDictionary(xDTM2,response2,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet28<-generateDictionary(xDTM2,response2,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet29<-generateDictionary(xDTM2,response2,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
dict_enet210<-generateDictionary(xDTM2,response2,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
summary(dict_enet21)
summary(dict_enet22)
summary(dict_enet23)
summary(dict_enet24)
summary(dict_enet25)
summary(dict_enet26)
summary(dict_enet27)
summary(dict_enet28)
summary(dict_enet29)
summary(dict_enet210)
write(dict_enet25, "dictionarys/enet-2level.dict")
summary(dict_enet25)
plot(dict_enet25)
dict_ridge2<-generateDictionary(xDTM2,response2,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
summary(dict_ridge2)
dict_ridge2<-generateDictionary(xDTM2,response2,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
summary(dict_ridge2)
write(dict_ridge2, "dictionarys/ridge-2level.dict")
=======
#1024
dict_lasso5<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
summary(dict_lasso5)
View(ridge_5lvl)
View(twitter_data_sentiment_5lvl)
#6235
dict_ridge5<-generateDictionary(xDTM5,response5,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
summary(dict_ridge5)
plot(dict_lasso5)
twitter_data_sentiment_3lvl<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub("0.5","1.0", sentimentScore, fixed = TRUE))
twitter_data_sentiment_3lvl<-twitter_data_sentiment_3lvl%>%select("sentimentScore", "text")
twitter_data_sentiment_3lvl$sentimentScore<-as.numeric(as.character(twitter_data_sentiment_3lvl$sentimentScore))
x3<-transformIntoCorpus(twitter_data_sentiment_3lvl$text)
response3<-twitter_data_sentiment_3lvl$sentimentScore
#1241
dict_lasso3<-generateDictionary(xDTM3,response3,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
xDTM3<-toDocumentTermMatrix(x3, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE)
response3<-twitter_data_sentiment_3lvl$sentimentScore
#1241
dict_lasso3<-generateDictionary(xDTM3,response3,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, language = "german")
summary(dict_lasso3)
compareDictionaries(dict_enet_2level,dict_enet_5level)
compareDictionaries(dict_enet_2level,dict_enet_5level)
compareDictionaries(dict_enet_3level,dict_enet_2level)
compareDictionaries(dict_enet_3level,dict_enet_5level)
require(tidyverse)
require(dplyr)
require(plyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
twitter_data_sentiment<-read_delim("twitter data/SentimentAnalyse#1.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_david_snd<-read_delim("data/SentimentAnalyseDavidzweiterDurchlauf.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_jakob_snd<-read_delim("twitter data/SentimentAnalyse#2.csv",
";", escape_double = FALSE, trim_ws = TRUE,
locale = locale())
colnames(twitter_data_sentiment_david_snd)<-c("sentimentScore","text")
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(ID))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%select(-c(X1,ID,positveSentimentScore,negativeSentimentScore))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%filter(sentimentScore != "NA")
twitter_data_sentiment_jakob_snd$isMatch<-"1"
twitter_data_sentiment_david_snd$isMatch<-"1"
twitter_data_sentiment<-rbind(twitter_data_sentiment,twitter_data_sentiment_jakob_snd,twitter_data_sentiment_david_snd)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
# Umwandeln der Scores in numeric mit "."
twitter_data_sentiment<-twitter_data_sentiment%>%filter(sentimentScore != "NA")
twitter_data_sentiment<-twitter_data_sentiment%>%filter(text != "")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment$sentimentScore<-as.numeric(as.character(twitter_data_sentiment$sentimentScore))
# Nur Matches der Kreuzvalid.
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_5lvl<-twitter_data_sentiment_match
twitter_data_sentiment_5lvl<-twitter_data_sentiment_5lvl%>%select("sentimentScore", "text")
response5<-twitter_data_sentiment_5lvl$sentimentScore
x5<-transformIntoCorpus(twitter_data_sentiment_5lvl$text)
xDTM5<-toDocumentTermMatrix(x5, language = "german", minWordLength = 3,
sparsity = 0.99999999, removeStopwords = TRUE, stemming = FALSE)
#1024
dict_lasso5<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
summary(dict_lasso5)
#Test
test_dict <- generateDictionary(x5,response= response5x, modelType = "lasso", sparsity = 0.9999999, weighting = function(x))
#Test
test_dict <- generateDictionary(x5,response= response5x, modelType = "lasso", sparsity = 0.9999999, weighting = function(x)
#Test
test_dict <- generateDictionary(x5,response= response5x, modelType = "lasso", sparsity = 0.9999999)
test_dict
#Test
test_dict <- generateDictionary(x5,response5, modelType = "lasso", sparsity = 0.9999999)
test_dict
#Test
test_dict <- generateDictionary(x5,response5, modelType = "lasso", sparsity = 0.9999999, weighting = function(x) tm::weightTfIdf(x, normalize =
FALSE))
summary(test_dict)
#Test
test_dict <- generateDictionary(x5,response5, modelType = "lasso", sparsity = 0.9999999,
weighting = function(x) tm::weightTfIdf(x, normalize=TRUE))
summary(test_dict)
#1024
dict_lasso5<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
compareDictionaries(dict_lasso5,test_dict)
>>>>>>> d271a4e3c3d377a1669a075c85075c72c01bc592
