dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999)
View(text)
response
twitter_data_sentiment_match[,c("sentimentScore")]<-sapply([,c("sentimentScore")],as.numeric)
twitter_data_sentiment_match[,c("sentimentScore")]<-sapply(twitter_data_sentiment_match[,c("sentimentScore")],as.numeric)
View(twitter_data_sentiment_match)
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
twitter_data_sentiment_match[,"sentimentScore"]<-sapply(twitter_data_sentiment_match[,"sentimentScore"],as.numeric)
View(twitter_data_sentiment_match)
str(twitter_data_sentiment_match)
twitter_data_sentiment_match[,"sentimentScore"]<-sapply(twitter_data_sentiment_match[,"sentimentScore"],as.factor)
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
str(twitter_data_sentiment_match)
twitter_data_sentiment_match[,"sentimentScore"]<-sapply(twitter_data_sentiment_match[,"sentimentScore"],as.numeric)
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%filter(sentimentScore != "NA")
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE))
View(dict)
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = FALSE), language = "german")
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language =  "german")
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
View(x)
View(x)
x<-transformIntoCorpus(twitter_data_sentiment_match$text, language = "german")
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
cleanTweetText<-function(text){
require(stringr)
require(stringi)
hashtag_pattern <- "#([[:alnum:]]|[_])+"
mention_pattern <- "@([[:alnum:]]|[_])+"
strip_RT_pattern<-"RT\\s@([[:alnum:]]|[_])+:"
#Die URLs und Mentions werden entfernt
text<-str_replace_all(text,pattern=mention_pattern,replacement="")
#W√∂rter die weniger als 3 Zeichen haben m√ºssen weg au√üer sie haben #
text<-str_replace_all(text,pattern="(?<!#)\\b[a-zA-Z0-9]{1,2}\\b",replacement = "")
#depends on whether you wanna keep hashtags or not
text<-str_replace_all(text,pattern="#",replacement="")
#Konvertierung von Umlauten
text<-stri_replace_all_fixed(text,
#c("?", "?", "?", "?", "?", "?"),
c("\U00E4","\U00F6","\U00FC","\U00C4","\U00D6","\U00DC"),
c("ae", "oe", "ue", "Ae", "Oe", "Ue"), vectorize_all = FALSE)
#Entfernung von Emoticons
text<-iconv(text, "latin1", "ASCII", sub="")
#Zahlen au√üer IN Hashtags
text<-str_replace_all(text,pattern="\\b\\d+\\b",replacement="")
#Satzzeichen und Special Characters au√üer # m√ºssen weg
text<-str_replace_all(text,pattern="[^[:alnum:]#]",replacement=" ")
text<-str_to_lower(text)
return(text)
}
#checkCleaner<-c("This is a üíÅ test #eu string .with @mention and #hashtag but d. u. also with http://www.ur.de !","And another string https://t.co/9aNUY4ZacF with to","we want; to keep #g20 or #r2g but, not 70 or 100 ...")
#cleanTweetText(checkCleaner)
checkCleaner<-c("This is a üíÅ test #eu string .with @mention and #hashtag but d. u. also with http://www.ur.de !","And another string https://t.co/9aNUY4ZacF with to","we want; to keep #g20 or #r2g but, not 70 or 100 ...")
cleanTweetText(checkCleaner)
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
# Aufbereiten Twitter Datensatz
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
#Entfernt alle Links (http(s) und alle Zeichen bis zum n√§chsten Leerzeichen)
twitter_data$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data$text)
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
#Entfernt alle abgeschnittenen Links
twitter_data$text<-gsub("htt[p]?\U2026","",twitter_data$text)
#Entfernen von abgeschnittenen Tweets
twitter_data<-twitter_data[!grepl("\U2026", twitter_data_sentiment$text),]
#Entfernen von abgeschnittenen Tweets
twitter_data<-twitter_data[!grepl("\U2026", twitter_data$text),]
View(twitter_data)
cleanTweetText<-function(text){
require(stringr)
require(stringi)
hashtag_pattern <- "#([[:alnum:]]|[_])+"
mention_pattern <- "@([[:alnum:]]|[_])+"
strip_RT_pattern<-"RT\\s@([[:alnum:]]|[_])+:"
#Die URLs und Mentions werden entfernt
text<-str_replace_all(text,pattern=mention_pattern,replacement="")
#W√∂rter die weniger als 3 Zeichen haben m√ºssen weg au√üer sie haben #
text<-str_replace_all(text,pattern="(?<!#)\\b[a-zA-Z0-9]{1,2}\\b",replacement = "")
#depends on whether you wanna keep hashtags or not
text<-str_replace_all(text,pattern="#",replacement="")
#Entfernung der Unicode Character <U+...>
test<-str_replace_all(text,pattern="\\<.?\\>",replacement="")
#Konvertierung von Umlauten
text<-stri_replace_all_fixed(text,
#c("?", "?", "?", "?", "?", "?"),
c("\U00E4","\U00F6","\U00FC","\U00C4","\U00D6","\U00DC"),
c("ae", "oe", "ue", "Ae", "Oe", "Ue"), vectorize_all = FALSE)
#Entfernung von Emoticons
text<-iconv(text, "latin1", "ASCII", sub="")
#Zahlen au√üer IN Hashtags
text<-str_replace_all(text,pattern="\\b\\d+\\b",replacement="")
#Satzzeichen und Special Characters au√üer # m√ºssen weg
text<-str_replace_all(text,pattern="[^[:alnum:]#]",replacement=" ")
text<-str_to_lower(text)
return(text)
}
#checkCleaner<-c("This is a üíÅ test #eu string .with @mention and #hashtag but d. u. also with http://www.ur.de !","And another string https://t.co/9aNUY4ZacF with to","we want; to keep #g20 or #r2g but, not 70 or 100 ...")
#cleanTweetText(checkCleaner)
#CleanTweetText auf den gesamten Twitter Datensatz
twitter_data<-twitter_data%>%mutate(text=cleanTweetText(text))
# Einlesen
twitter_data_sentiment_david<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
# Spalten S√§ubern (ID leider verf√§lscht)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
# Fehlerhaft bei √§,√º,√∂
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
View(twitter_data_sentiment)
# Einlesen
twitter_data_sentiment_david<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
# Spalten S√§ubern (ID leider verf√§lscht)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
# S√§ubern
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
# Fehlerhaft bei √§,√º,√∂
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
# Nur Matches der Kreuzvalid.
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
# Umwandeln der Scores in numeric mit "."
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment_match[,"sentimentScore"]<-sapply(twitter_data_sentiment_match[,"sentimentScore"],as.numeric)
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%filter(sentimentScore != "NA")
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
View(dict)
summary(dict)
dict
require(tidyverse)
require(dplyr)
require(plyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
dict_level3<-generateDictionary(x_level3,response_level3,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
baseline_dict_level3<-read_delim("data/SentimentForDict3LevelSkala.csv",
";", escape_double = FALSE, trim_ws = TRUE)
baseline_dict_level5<-read_delim("data/SentimentforDict5LevelSkala.csv",
";", escape_double = FALSE, trim_ws = FALSE)
#Erstellen des Dictornary auf Level 3 Baseline
x_level3<-transformIntoCorpus(sbaseline_dict_level3$text)
#Erstellen des Dictornary auf Level 3 Baseline
x_level3<-transformIntoCorpus(baseline_dict_level3$text)
response_level3<-as.numeric(as.character(baseline_dict_level3$sentimenScore))
dict_level3<-generateDictionary(x_level3,response_level3,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
#only selecting the text column for sentiment analyses
twitter_data_for_sentiment<-twitter_data%>%select("text")
#only selecting the text column for sentiment analyses
twitter_data_for_sentiment<-twitter_data%>%select("text")
twitter_data_for_sentiment<-twitter_data%>%select("text")
summary(dict_level3)
require(tidyverse)
require(dplyr)
require(plyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
View(twitter_data_for_sentiment)
sentiment <-predict(dict_level3,twitter_data_for_sentiment$text)
View(sentiment)
mapply(c,twitter_data_for_sentiment, sentiment, SIMPLIFY = FALSE)
com <-mapply(c,twitter_data_for_sentiment, sentiment, SIMPLIFY = FALSE)
View(com)
View(com)
View(com)
twitter_data_for_sentiment<-twitter_data_for_sentiment%>%mutate(sentimentScore=NA)
View(twitter_data_for_sentiment)
twitter_data_forsentiment$sentimentScore<-sentiment
twitter_data_for_sentiment$sentimentScore<-sentiment
View(twitter_data_for_sentiment)
twitter_data_for_sentiment<-twitter_data_for_sentiment[1:1000,]
twitter_data_for_sentiment<-twitter_data_for_sentiment[1:1000,]
#only selecting the text column for sentiment analyses
twitter_data_for_sentiment<-twitter_data%>%select("text")
twitter_data_for_sentiment<-twitter_data_for_sentiment[1:1000,]
sentiment <-predict(dict_level3,twitter_data_for_sentiment$text)
twitter_data_for_sentiment<-twitter_data_for_sentiment%>%mutate(sentimentScore=NA)
twitter_data_for_sentiment$sentimentScore<-sentiment
View(twitter_data_for_sentiment)
plotSentiment(sentiment)
plotSentimentResponse(sentiment,x_leve3)
#Erstellen des Dictornary auf Level 3 Baseline
x_level3<-transformIntoCorpus(baseline_dict_level3$text)
plotSentimentResponse(sentiment,x_level3)
hist(sentiment)
hist(as.numeric(sentiment))
hist(as.numeric(unlist(sentiment)))
twitter_data_for_sentiment<-twitter_data_for_sentiment[1:30000,]
#only selecting the text column for sentiment analyses
twitter_data_for_sentiment<-twitter_data%>%select("text")
twitter_data_for_sentiment<-twitter_data_for_sentiment[1:30000,]
sentiment <-predict(dict_level3,twitter_data_for_sentiment$text)
twitter_data_for_sentiment<-twitter_data_for_sentiment%>%mutate(sentimentScore=NA)
twitter_data_for_sentiment$sentimentScore<-sentiment
hist(as.numeric(unlist(sentiment)))
View(twitter_data)
dict_level3<-generateDictionary(x_level3,response_level3,modelType = "ridge", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
#only selecting the text column for sentiment analyses
twitter_data_for_sentiment<-twitter_data%>%select("text")
twitter_data_for_sentiment<-twitter_data_for_sentiment[1:30000,]
twitter_data_for_sentiment<-twitter_data_for_sentiment%>%mutate(sentimentScore=NA)
sentiment <-predict(dict_level3,twitter_data_for_sentiment$text)
twitter_data_for_sentiment$sentimentScore<-sentiment
hist(as.numeric(unlist(sentiment)))
dict_level5<-generateDictionary(x_level5,response_level5,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
#Erstellen des Dict auf Level 5 Baseline
x_level5<-transformIntoCorpus(baseline_dict_level5$text)
response_level5<-as.numeric(as.character(baseline_dict_level5$sentimentScore))
dict_level5<-generateDictionary(x_level5,response_level5,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
compareDictionaries(dict_level3,dict_level5)
dict_level3<-generateDictionary(x_level3,response_level3,modelType = "ridge", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.9, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
summary(dict_level3)
dict_level3<-generateDictionary(x_level3,response_level3,modelType = "ridge", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.95, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
summary(dict_level3)
dict_level3<-generateDictionary(x_level3,response_level3,modelType = "ridge", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
summary(dict_level3)
dict_level3
dict_level3<-generateDictionary(x_level3,response_level3,modelType = "enet", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.999999999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
summary(dict_level3)
#only selecting the text column for sentiment analyses
twitter_data_for_sentiment<-twitter_data%>%select("text")
twitter_data_for_sentiment<-twitter_data_for_sentiment[1:30000,]
sentiment <-predict(dict_level3,twitter_data_for_sentiment$text)
twitter_data_for_sentiment<-twitter_data_for_sentiment%>%mutate(sentimentScore=NA)
twitter_data_for_sentiment$sentimentScore<-sentiment
hist(as.numeric(unlist(sentiment)))
dict_level3
twitter_data_sentiment_3lvl<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub("0.5","1.0", sentimentScore, fixed = TRUE))
require(tidyverse)
require(dplyr)
require(plyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
twitter_data_sentiment_3lvl<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub("0.5","1.0", sentimentScore, fixed = TRUE))
twitter_data_sentiment_3lvl<-twitter_data_sentiment_3lvl%>%select("sentimentScore", "text")
write.csv(twitter_data_sentiment_3lvl, "data/SentimentAnalyse_3LevelDict")
x3<-transformIntoCorpus(twitter_data_sentiment_3lvl$text)
xDTM3<-toDocumentTermMatrix(x3, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE,
weighting = function(x) tm::weightTfIdf(x, normalize = FALSE))
response3<-twitter_data_sentiment_3lvl$sentimentScore
dict_lasso3<-generateDictionary(xDTM3,response3,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment[,"sentimentScore"]<-sapply(twitter_data_sentiment[,"sentimentScore"],as.numeric)
twitter_data_sentiment<-twitter_data_sentiment%>%filter(sentimentScore != "NA")
twitter_data_sentiment<-twitter_data_sentiment%>%filter(sentimentScore != "NA")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment[,"sentimentScore"]<-sapply(twitter_data_sentiment[,"sentimentScore"],as.numeric)
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_3lvl<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub("0.5","1.0", sentimentScore, fixed = TRUE))
twitter_data_sentiment_3lvl<-twitter_data_sentiment_3lvl%>%select("sentimentScore", "text")
write.csv(twitter_data_sentiment_3lvl, "data/SentimentAnalyse_3LevelDict")
x3<-transformIntoCorpus(twitter_data_sentiment_3lvl$text)
xDTM3<-toDocumentTermMatrix(x3, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE,
weighting = function(x) tm::weightTfIdf(x, normalize = FALSE))
response3<-twitter_data_sentiment_3lvl$sentimentScore
dict_lasso3<-generateDictionary(xDTM3,response3,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
View(twitter_data_sentiment_3lvl)
twitter_data_sentiment_3lvl[,"sentimentScore"]<-sapply(twitter_data_sentiment_3lvl[,"sentimentScore"],as.numeric)
View(twitter_data_sentiment_3lvl)
twitter_data_sentiment<-read_delim("twitter data/SentimentAnalyse#1.csv",";"
,escape_double = FALSE, trim_ws =TRUE)
twitter_data_sentiment_david_snd<-read_delim("data/SentimentAnalyseDavidzweiterDurchlauf.csv",";"
,escape_double = FALSE, trim_ws =TRUE)
twitter_data_sentiment_jakob_snd<-read_delim("twitter data/SentimentAnalyse#2.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment<-read_delim("twitter data/SentimentAnalyse#1.csv",";"
,escape_double = FALSE, trim_ws =TRUE)
twitter_data_sentiment_david_snd<-read_delim("data/SentimentAnalyseDavidzweiterDurchlauf.csv",";"
,escape_double = FALSE, trim_ws =TRUE)
twitter_data_sentiment_jakob_snd<-read_delim("twitter data/SentimentAnalyse#2.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_david_snd)<-c("sentimentScore","text")
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(ID))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%select(-c(X1,ID,positveSentimentScore,negativeSentimentScore))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%filter(sentimentScore != "NA")
twitter_data_sentiment_jakob_snd$isMatch<-"1"
twitter_data_sentiment_david_snd$isMatch<-"1"
twitter_data_sentiment<-rbind(twitter_data_sentiment,twitter_data_sentiment_jakob_snd,twitter_data_sentiment_david_snd)
twitter_data_sentiment$text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("https","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
twitter_data_sentiment$text<-gsub("<e4>","√§",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("<c4>","√Ñ",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("<d6>","√ñ",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("<dc>","√ú",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("<f6>","√∂",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("<fc>","√º",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("<[^\\s]+>","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("<[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("&amp;","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
twitter_data_sentiment<-twitter_data_sentiment%>%filter(sentimentScore != "NA")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment[,"sentimentScore"]<-sapply(twitter_data_sentiment[,"sentimentScore"],as.numeric)
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_3lvl<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub("0.5","1.0", sentimentScore, fixed = TRUE))
twitter_data_sentiment_3lvl<-twitter_data_sentiment_3lvl%>%select("sentimentScore", "text")
write.csv(twitter_data_sentiment_3lvl, "data/SentimentAnalyse_3LevelDict")
x3<-transformIntoCorpus(twitter_data_sentiment_3lvl$text)
xDTM3<-toDocumentTermMatrix(x3, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE,
weighting = function(x) tm::weightTfIdf(x, normalize = FALSE))
response3<-twitter_data_sentiment_3lvl$sentimentScore
twitter_data_sentiment_3lvl[,"sentimentScore"]<-sapply(twitter_data_sentiment_3lvl[,"sentimentScore"],as.numeric)
x3<-transformIntoCorpus(twitter_data_sentiment_3lvl$text)
xDTM3<-toDocumentTermMatrix(x3, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE,
weighting = function(x) tm::weightTfIdf(x, normalize = FALSE))
twitter_data_sentiment$sentimentScore<-as.numeric(as.character(twitter_data_sentiment$sentimentScore))
View(twitter_data_sentiment)
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_3lvl<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub("0.5","1.0", sentimentScore, fixed = TRUE))
twitter_data_sentiment_3lvl<-twitter_data_sentiment_3lvl%>%select("sentimentScore", "text")
x3<-transformIntoCorpus(twitter_data_sentiment_3lvl$text)
xDTM3<-toDocumentTermMatrix(x3, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE,
weighting = function(x) tm::weightTfIdf(x, normalize = FALSE))
twitter_data_sentiment_3lvl$sentimentScore<-as.numeric(as.character(twitter_data_sentiment_3lvl$sentimentScore))
xDTM3<-toDocumentTermMatrix(x3, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE,
weighting = function(x) tm::weightTfIdf(x, normalize = FALSE))
x3<-transformIntoCorpus(twitter_data_sentiment_3lvl$text)
xDTM3<-toDocumentTermMatrix(x3, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE,
weighting = function(x) tm::weightTfIdf(x, normalize = FALSE))
View(twitter_data_sentiment_3lvl)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
require(tidyverse)
require(dplyr)
require(plyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
twitter_data_sentiment<-twitter_data_sentiment%>%filter(sentimentScore != "NA")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment$sentimentScore<-as.numeric(as.character(twitter_data_sentiment$sentimentScore))
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_3lvl<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub("0.5","1.0", sentimentScore, fixed = TRUE))
twitter_data_sentiment_3lvl<-twitter_data_sentiment_3lvl%>%select("sentimentScore", "text")
twitter_data_sentiment_3lvl$sentimentScore<-as.numeric(as.character(twitter_data_sentiment_3lvl$sentimentScore))
write.csv(twitter_data_sentiment_3lvl, "data/SentimentAnalyse_3LevelDict")
x3<-transformIntoCorpus(twitter_data_sentiment_3lvl$text)
xDTM3<-toDocumentTermMatrix(x3, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE,
weighting = function(x) tm::weightTfIdf(x, normalize = FALSE))
response3<-twitter_data_sentiment_3lvl$sentimentScore
dict_lasso3<-generateDictionary(xDTM3,response3,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
summary(dict_lasso3)
plot(dict_lasso3)
dict_lm3<-generateDictionary(xDTM3,response,modelType = "lm", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_enet3<-generateDictionary(xDTM3,response,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_ridge3<-generateDictionary(xDTM3,response,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_lm3<-generateDictionary(xDTM3,response3,modelType = "lm", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_enet3<-generateDictionary(xDTM3,response3,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_ridge3<-generateDictionary(xDTM3,response3,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
summary(dict_lm3)
plot(dict_lm3)
summary(dict_enet3)
plot(dict_enet3)
summary(dict_ridge3)
plot(dict_ridge3)
twitter_data_sentiment_2lvl<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub("0.5","1", sentimentScore, fixed = TRUE))
twitter_data_sentiment_2lvl<-twitter_data_sentiment_2lvl%>%filter(sentimentScore != 0)
twitter_data_sentiment_2lvl<-twitter_data_sentiment_2lvl%>%select("sentimentScore", "text")
twitter_data_sentiment_2lvl$sentimentScore<-as.numeric(as.character(twitter_data_sentiment_2lvl$sentimentScore))
write.csv(twitter_data_sentiment_2lvl, "data/SentimentAnalyse_2LevelDict")
x2<-transformIntoCorpus(twitter_data_sentiment_2lvl$text)
xDTM2<-toDocumentTermMatrix(x2, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE,
weighting = function(x) tm::weightTfIdf(x, normalize = FALSE))
response2<-twitter_data_sentiment_2lvl$sentimentScore
dict_lasso2<-generateDictionary(xDTM2,response2,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_lm2<-generateDictionary(xDTM2,response2,modelType = "lm", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_enet2<-generateDictionary(xDTM2,response2,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_ridge2<-generateDictionary(xDTM2,response2,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
summary(dict_lasso2)
plot(dict_lasso2)
summary(dict_lm2)
plot(dict_lm2)
summary(dict_enet2)
plot(dict_enet2)
summary(dict_ridge2)
plot(dict_ridge2)
View(twitter_data_sentiment)
require(SnowballC)
?SnowballC
??SnowballC
twitter_data[1,]
source("r scripts/cleanTweetText.R")
require(tidyverse)
require(dplyr)
require(plyr)
library(readr)
twitter_data<-read_csv("twitter data/twitter_data.csv",
locale = locale())
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
twitter_data$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data$text)
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
twitter_data$text<-gsub("https","",twitter_data$text)
twitter_data$text<-gsub("http","",twitter_data$text)
twitter_data<-twitter_data[!grepl("\U2026", twitter_data$text),]
twitter_data$text<-gsub("htt[p]?\U2026","",twitter_data$text)
twitter_data<-twitter_data%>%mutate(text=cleanTweetText(text))
twitter_data[1,]
twitter_data[1,]$text
wordStem(twitter_data[1,]$text)
wordStem(twitter_data[1,]$text, language="german")
twitter_data[2,]$text
wordStem(twitter_data[2,]$text, language="german")
twitter_data[3:10,]$text
wordStem(twitter_data[3:10,]$text, language="german")
wordStem(twitter_data[3:10,]$text, language="porter")
wordStem(as.character(twitter_data[3:10,]$text), language="german")
wordStem("geschossen",language="german")
