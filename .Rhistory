require(stringr)
require(stringi)
hashtag_pattern <- "#([[:alnum:]]|[_])+"
mention_pattern <- "@([[:alnum:]]|[_])+"
strip_RT_pattern<-"RT\\s@([[:alnum:]]|[_])+:"
#Die URLs und Mentions werden entfernt
text<-str_replace_all(text,pattern=mention_pattern,replacement="")
#W√∂rter die weniger als 3 Zeichen haben m√ºssen weg au√üer sie haben #
text<-str_replace_all(text,pattern="(?<!#)\\b[a-zA-Z0-9]{1,2}\\b",replacement = "")
#depends on whether you wanna keep hashtags or not
text<-str_replace_all(text,pattern="#",replacement="")
#Konvertierung von Umlauten
text<-stri_replace_all_fixed(text,
#c("?", "?", "?", "?", "?", "?"),
c("\U00E4","\U00F6","\U00FC","\U00C4","\U00D6","\U00DC"),
c("ae", "oe", "ue", "Ae", "Oe", "Ue"), vectorize_all = FALSE)
#Entfernung von Emoticons
text<-iconv(text, "latin1", "ASCII", sub="")
#Zahlen au√üer IN Hashtags
text<-str_replace_all(text,pattern="\\b\\d+\\b",replacement="")
#Satzzeichen und Special Characters au√üer # m√ºssen weg
text<-str_replace_all(text,pattern="[^[:alnum:]#]",replacement=" ")
text<-str_to_lower(text)
return(text)
}
#checkCleaner<-c("This is a üíÅ test #eu string .with @mention and #hashtag but d. u. also with http://www.ur.de !","And another string https://t.co/9aNUY4ZacF with to","we want; to keep #g20 or #r2g but, not 70 or 100 ...")
#cleanTweetText(checkCleaner)
checkCleaner<-c("This is a üíÅ test #eu string .with @mention and #hashtag but d. u. also with http://www.ur.de !","And another string https://t.co/9aNUY4ZacF with to","we want; to keep #g20 or #r2g but, not 70 or 100 ...")
cleanTweetText(checkCleaner)
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
twitter_data<-read_csv("data/twitter_data.csv",
locale = locale())
# Aufbereiten Twitter Datensatz
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
#Entfernt alle Links (http(s) und alle Zeichen bis zum n√§chsten Leerzeichen)
twitter_data$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data$text)
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
#Entfernt alle abgeschnittenen Links
twitter_data$text<-gsub("htt[p]?\U2026","",twitter_data$text)
#Entfernen von abgeschnittenen Tweets
twitter_data<-twitter_data[!grepl("\U2026", twitter_data_sentiment$text),]
#Entfernen von abgeschnittenen Tweets
twitter_data<-twitter_data[!grepl("\U2026", twitter_data$text),]
View(twitter_data)
cleanTweetText<-function(text){
require(stringr)
require(stringi)
hashtag_pattern <- "#([[:alnum:]]|[_])+"
mention_pattern <- "@([[:alnum:]]|[_])+"
strip_RT_pattern<-"RT\\s@([[:alnum:]]|[_])+:"
#Die URLs und Mentions werden entfernt
text<-str_replace_all(text,pattern=mention_pattern,replacement="")
#W√∂rter die weniger als 3 Zeichen haben m√ºssen weg au√üer sie haben #
text<-str_replace_all(text,pattern="(?<!#)\\b[a-zA-Z0-9]{1,2}\\b",replacement = "")
#depends on whether you wanna keep hashtags or not
text<-str_replace_all(text,pattern="#",replacement="")
#Entfernung der Unicode Character <U+...>
test<-str_replace_all(text,pattern="\\<.?\\>",replacement="")
#Konvertierung von Umlauten
text<-stri_replace_all_fixed(text,
#c("?", "?", "?", "?", "?", "?"),
c("\U00E4","\U00F6","\U00FC","\U00C4","\U00D6","\U00DC"),
c("ae", "oe", "ue", "Ae", "Oe", "Ue"), vectorize_all = FALSE)
#Entfernung von Emoticons
text<-iconv(text, "latin1", "ASCII", sub="")
#Zahlen au√üer IN Hashtags
text<-str_replace_all(text,pattern="\\b\\d+\\b",replacement="")
#Satzzeichen und Special Characters au√üer # m√ºssen weg
text<-str_replace_all(text,pattern="[^[:alnum:]#]",replacement=" ")
text<-str_to_lower(text)
return(text)
}
#checkCleaner<-c("This is a üíÅ test #eu string .with @mention and #hashtag but d. u. also with http://www.ur.de !","And another string https://t.co/9aNUY4ZacF with to","we want; to keep #g20 or #r2g but, not 70 or 100 ...")
#cleanTweetText(checkCleaner)
#CleanTweetText auf den gesamten Twitter Datensatz
twitter_data<-twitter_data%>%mutate(text=cleanTweetText(text))
# Einlesen
twitter_data_sentiment_david<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
# Spalten S√§ubern (ID leider verf√§lscht)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
# Fehlerhaft bei √§,√º,√∂
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
View(twitter_data_sentiment)
# Einlesen
twitter_data_sentiment_david<-read_delim("data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
# Spalten S√§ubern (ID leider verf√§lscht)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
# S√§ubern
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
# Fehlerhaft bei √§,√º,√∂
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
# Nur Matches der Kreuzvalid.
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
# Umwandeln der Scores in numeric mit "."
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment_match[,"sentimentScore"]<-sapply(twitter_data_sentiment_match[,"sentimentScore"],as.numeric)
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%filter(sentimentScore != "NA")
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
View(dict)
summary(dict)
dict
require(tidyverse)
require(dplyr)
require(plyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
dict<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(),
minWordLength = 3, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
summary(dict)
dict_lm<-generateDictionary(x,response,modelType = "lm", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
summary(dict_lm)
plot(dict_lm)
dict_lm<-generateDictionary(x,response,modelType = "lm", filterTerms = NULL, sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
summary(dict_lm)
plot(dict_lm)
dict_enet<-generateDictionary(x,response,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
summary(dict_enet)
plot(dict_enet)
dict_enet
dict_ridge<-generateDictionary(x,response,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
summary(dict_ridge)
plot(dict_ridge)
dict_ridge
summary(dict_ridge)
require(tidyverse)
require(dplyr)
require(plyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%filter(sentimentScore != 0)
dict_lasso_pol<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict_lasso_pol<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
dict_lm_pol<-generateDictionary(x,response,modelType = "lm", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
dict_enet_pol<-generateDictionary(x,response,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
dict_ridge_pol<-generateDictionary(x,response,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
plot(dict_lasso_pol)
plot(dict_lm_pol)
plot(dict_enet_pol)
plot(dict_ridge_pol)
plot(dict_enet_pol)
dict_lasso_pol<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
plot(dict_lasso_pol)
dict_lm_pol<-generateDictionary(x,response,modelType = "lm", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
plot(dict_lm_pol)
dict_enet_pol<-generateDictionary(x,response,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
plot(dict_enet_pol)
dict_ridge_pol<-generateDictionary(x,response,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
plot(dict_ridge_pol)
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub("0.5","1", sentimentScore, fixed = TRUE))
View(twitter_data_sentiment_match)
dict_lasso_pol<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_lm_pol<-generateDictionary(x,response,modelType = "lm", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_enet_pol<-generateDictionary(x,response,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
dict_ridge_pol<-generateDictionary(x,response,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
plot(dict_lasso_pol)
plot(dict_lm_pol)
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict_lasso_pol<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_lm_pol<-generateDictionary(x,response,modelType = "lm", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_enet_pol<-generateDictionary(x,response,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
dict_ridge_pol<-generateDictionary(x,response,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE))
plot(dict_lasso_pol)
summary(dict_lasso_pol)
plot(dict_lm_pol)
plot(dict_enet_pol)
plot(dict_ridge_pol)
dict_enet_pol<-generateDictionary(x,response,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_ridge_pol<-generateDictionary(x,response,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
plot(dict_enet_pol)
plot(dict_ridge_pol)
summary(dict_ridge)
summary(dict_ridge_pol)
dict_ridge_pol
twitter_data_sentiment_david<-read_delim("twitter data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("twitter data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
twitter_data_sentiment$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
View(twitter_data_sentiment)
twitter_data_sentiment$text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
View(twitter_data_sentiment)
twitter_data_sentiment$text<-gsub("http | https","",twitter_data_sentiment$text)
twitter_data_sentiment_david<-read_delim("twitter data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("twitter data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
twitter_data_sentiment$text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http | https","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
twitter_data_sentiment$text<-gsub("http || https","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http" | "https","",twitter_data_sentiment$text)
twitter_data_sentiment_david<-read_delim("twitter data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("twitter data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
twitter_data_sentiment$text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("[http]*[https]*","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment_match[,"sentimentScore"]<-sapply(twitter_data_sentiment_match[,"sentimentScore"],as.numeric)
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%filter(sentimentScore != "NA")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%filter(sentimentScore != 0)
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub("0.5","1", sentimentScore, fixed = TRUE))
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict_lasso_pol<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
plot(dict_lasso_pol)
View(twitter_data_sentiment_match)
twitter_data_sentiment$text<-gsub("http","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http","",twitter_data_sentiment$text)
twitter_data_sentiment_david<-read_delim("twitter data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("twitter data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
# Spalten S√§ubern (ID leider verf√§lscht)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
# S√§ubern
twitter_data_sentiment$text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment_match[,"sentimentScore"]<-sapply(twitter_data_sentiment_match[,"sentimentScore"],as.numeric)
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%filter(sentimentScore != "NA")
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%filter(sentimentScore != 0)
twitter_data_sentiment_match<-twitter_data_sentiment_match%>%mutate(sentimentScore = sub("0.5","1", sentimentScore, fixed = TRUE))
x<-transformIntoCorpus(twitter_data_sentiment_match$text)
response<-as.numeric(as.character(twitter_data_sentiment_match$sentimentScore))
dict_lasso_pol<-generateDictionary(x,response,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
plot(dict_lasso_pol)
dict_lm_pol<-generateDictionary(x,response,modelType = "lm", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_enet_pol<-generateDictionary(x,response,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_ridge_pol<-generateDictionary(x,response,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
plot(dict_lm_pol)
plot(dict_enet_pol)
plot(dict_ridge_pol)
twitter_data<-read_csv("twitter data/twitter_data.csv",
locale = locale())
View(twitter_data)
twitter_data<-twitter_data%>%select(c("ID","positiveSentimentScore","negativeSentimentScore","text"))
twitter_data<-twitter_data%>%select(c("ID","positveSentimentScore","negativeSentimentScore","text"))
View(twitter_data)
twitter_data<-twitter_data[order("positveSentimentScore"),]
View(twitter_data)
twitter_data<-read_csv("twitter data/twitter_data.csv",
locale = locale())
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
twitter_data$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data$text)
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
twitter_data$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data$text)
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
twitter_data_sentiment$text<-gsub("https","",twitter_data_sentiment$text)
twitter_data$text<-gsub("https","",twitter_data$text)
twitter_data$text<-gsub("http","",twitter_data$text)
twitter_data$text<-gsub("htt[p]?\U2026","",twitter_data$text)
twitter_data<-twitter_data[!grepl("\U2026", twitter_data$text),]
twitter_data_exp<-twitter_data%>%select(c("ID","positveSentimentScore","negativeSentimentScore","text"))
twitter_data_exp<-twitter_data[order("positveSentimentScore")]
View(twitter_data_exp)
twitter_data_exp<-twitter_data%>%select(c("ID","positveSentimentScore","negativeSentimentScore","text"))
twitter_data_exp<-twitter_data[order("positveSentimentScore"),]
twitter_data_exp<-twitter_data%>%select(c("ID","positveSentimentScore","negativeSentimentScore","text"))
twitter_data_exp<-twitter_data[order("positveSentimentScore","negativeSentimentScore")]
View(twitter_data_exp)
twitter_data_exp<-twitter_data%>%>arrange(desc("positveSentimentScore"),"negativeSentimentScore")
twitter_data_exp<-twitter_data%>%select(c("ID","positveSentimentScore","negativeSentimentScore","text"))
twitter_data_exp<-twitter_data%>%>arrange(desc("positveSentimentScore"),"negativeSentimentScore")
twitter_data_exp<-twitter_data%>%arrange(desc("positveSentimentScore"),"negativeSentimentScore")
View(twitter_data_exp)
twitter_data_exp<-twitter_data_exp%>%arrange(desc("positveSentimentScore"),"negativeSentimentScore")
twitter_data_exp<-twitter_data_exp%>%arrange(desc("positveSentimentScore"),"negativeSentimentScore")
View(twitter_data_exp)
twitter_data_exp<-twitter_data_exp%>%arrange(desc(positveSentimentScore),negativeSentimentScore)
View(twitter_data_exp)
twitter_data_exp<-twitter_data_exp%>%arrange(desc(positveSentimentScore),desc(negativeSentimentScore)
twitter_data_exp<-twitter_data_exp%>%arrange(desc(positveSentimentScore),desc(negativeSentimentScore))
twitter_data_exp<-twitter_data%>%select(c("ID","positveSentimentScore","negativeSentimentScore","text"))
twitter_data_exp<-twitter_data_exp%>%arrange(desc(positveSentimentScore),desc(negativeSentimentScore))
View(twitter_data_exp)
twitter_data_exp_pos<-head(twitter_data_exp,200)
View(twitter_data_exp_pos)
write(twitter_data_exp_pos, "twitter data/ExampleTweetsSentiStrength.csv")
write.csv(twitter_data_exp_pos, "twitter data/ExampleTweetsSentiStrength.csv")
write.csv(twitter_data_exp_pos, "twitter data/ExampleTweetsSentiStrengthPos.csv")
twitter_data_exp<-twitter_data%>%select(c("ID","positveSentimentScore","negativeSentimentScore","text"))
twitter_data_exp<-twitter_data_exp%>%arrange(negativeSentimentScore,positveSentimentScore)
View(twitter_data_exp)
twitter_data_exp_neg<-head(twitter_data_exp,200)
write.csv(twitter_data_exp_neg, "twitter data/ExampleTweetsSentiStrengthNeg.csv")
twitter_data_exp$sentimentScore<-""
twitter_data_exp<-twitter_data%>%select(c("ID","positveSentimentScore","negativeSentimentScore","text"))
twitter_data_exp$sentimentScore<-""
twitter_data_exp<-twitter_data_exp%>%arrange(desc(positveSentimentScore),desc(negativeSentimentScore))
twitter_data_exp_pos<-head(twitter_data_exp,200)
write.csv(twitter_data_exp_pos, "twitter data/ExampleTweetsSentiStrengthPos.csv")
twitter_data_exp<-twitter_data%>%select(c("ID","positveSentimentScore","negativeSentimentScore","text"))
twitter_data_exp$sentimentScore<-""
twitter_data_exp<-twitter_data_exp%>%arrange(negativeSentimentScore,positveSentimentScore)
twitter_data_exp_neg<-head(twitter_data_exp,200)
write.csv(twitter_data_exp_neg, "twitter data/ExampleTweetsSentiStrengthNeg.csv")
twitter_data_exp<-twitter_data%>%select(c("sentimentScore","ID","positveSentimentScore","negativeSentimentScore","text"))
twitter_data_exp<-twitter_data%>%select(c("ID","positveSentimentScore","negativeSentimentScore","text"))
twitter_data_exp$sentimentScore<-""
twitter_data_exp<-twitter_data_exp[c("ID","positveSentimentScore","negativeSentimentScore","sentimentScore","text")]
View(twitter_data_exp)
twitter_data_exp<-twitter_data_exp%>%arrange(desc(positveSentimentScore),desc(negativeSentimentScore))
twitter_data_exp_pos<-head(twitter_data_exp,200)
write.csv(twitter_data_exp_pos, "twitter data/ExampleTweetsSentiStrengthPos.csv")
twitter_data_exp<-twitter_data%>%select(c("ID","positveSentimentScore","negativeSentimentScore","text"))
twitter_data_exp$sentimentScore<-""
twitter_data_exp<-twitter_data_exp[c("ID","positveSentimentScore","negativeSentimentScore","sentimentScore","text")]
twitter_data_exp<-twitter_data_exp%>%arrange(negativeSentimentScore,positveSentimentScore)
twitter_data_exp_neg<-head(twitter_data_exp,200)
write.csv(twitter_data_exp_neg, "twitter data/ExampleTweetsSentiStrengthNeg.csv")
require(tidyverse)
require(dplyr)
require(plyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
twitter_data_exp<-twitter_data%>%select(c("ID","positveSentimentScore","negativeSentimentScore","text"))
twitter_data_exp$sentimentScore<-""
twitter_data_exp<-twitter_data_exp[c("ID","positveSentimentScore","negativeSentimentScore","sentimentScore","text")]
twitter_data_exp<-twitter_data_exp%>%arrange(desc(positveSentimentScore),desc(negativeSentimentScore))
twitter_data_exp_pos<-head(twitter_data_exp,200:400)
twitter_data_exp_pos<-twitter_data_exp_pos[c(200,400)]
twitter_data_exp_pos<-twitter_data_exp_pos[c(200:400)]
twitter_data_exp_pos<-twitter_data_exp_pos[c(200:400),]
write.csv(twitter_data_exp_pos, "twitter data/ExampleTweetsSentiStrengthPos.csv")
View(twitter_data_exp)
View(twitter_data_exp_pos)
twitter_data_exp_pos<-twitter_data_exp_pos[c(200,400),]
twitter_data_exp_pos<-twitter_data_exp_pos[200:400,]
twitter_data_exp_pos<-twitter_data_exp_pos[1:400,]
write.csv(twitter_data_exp_pos, "twitter data/ExampleTweetsSentiStrengthPos.csv")
View(twitter_data_exp_pos)
View(twitter_data_exp_pos)
View(twitter_data_exp)
twitter_data_exp<-twitter_data_exp%>%arrange(desc(positveSentimentScore),desc(negativeSentimentScore))
twitter_data_exp_pos<-twitter_data_exp_pos[1:400,]
View(twitter_data_exp_pos)
twitter_data_exp_pos<-twitter_data_exp_pos[1,]
twitter_data_exp_pos<-twitter_data_exp[1:400,]
View(twitter_data_exp_pos)
View(twitter_data_exp_pos)
write.csv(twitter_data_exp_pos, "twitter data/ExampleTweetsSentiStrengthPos.csv")
twitter_data_exp_neg<-twitter_data_exp[201:400,]
twitter_data_exp_neg<-twitter_data_exp[201:400,]
twitter_data_exp<-twitter_data_exp%>%arrange(negativeSentimentScore,positveSentimentScore)
twitter_data_exp_neg<-twitter_data_exp[201:400,]
write.csv(twitter_data_exp_neg, "twitter data/ExampleTweetsSentiStrengthNeg2.csv")
require(tidyverse)
require(dplyr)
require(plyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
xDM<-toDocumentTermMatrix(x, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE,
weighting = function(x) tm::weightTfIdf(x, normalize = FALSE))
dict_lasso_pol<-generateDictionary(xDM,response,modelType = "lasso", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_lasso_pol
summary(dict_lasso_pol)
View(twitter_data_sentiment_match)
View(twitter_data)
twitter_data<-read_csv("twitter data/twitter_data.csv",
locale = locale())
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
twitter_data$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data$text)
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
twitter_data$text<-gsub("https","",twitter_data$text)
twitter_data$text<-gsub("http","",twitter_data$text)
twitter_data$text<-gsub("htt[p]?\U2026","",twitter_data$text)
twitter_data<-twitter_data[!grepl("\U2026", twitter_data$text),]
twitter_data<-twitter_data%>%mutate(text=cleanTweetText(text))
twitter_data_sentiment_david<-read_delim("twitter data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("twitter data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
twitter_data_sentiment$text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("https","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_david<-read_delim("twitter data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("twitter data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
twitter_data_sentiment$text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("https","",twitter_data_sentiment$text)
twitter_data_sentiment$text<-gsub("http","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment[!grepl("\U2026", twitter_data_sentiment$text),]
twitter_data_sentiment_david<-read_delim("twitter data/SentimentAnalyseDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
twitter_data_sentiment_jakob<-read_delim("twitter data/SentimentAnalyseJakobMatchedFromDavid.csv",
";", escape_double = FALSE, trim_ws = TRUE)
colnames(twitter_data_sentiment_jakob)<-c("Nummer","ID","isMatch","sentimentScore","text")
twitter_data_sentiment_jakob<-twitter_data_sentiment_jakob[,c("Nummer","ID","sentimentScore","isMatch","text")]
twitter_data_sentiment<-rbind(twitter_data_sentiment_david,twitter_data_sentiment_jakob)
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(Nummer,ID))
View(twitter_data_sentiment_jakob)
