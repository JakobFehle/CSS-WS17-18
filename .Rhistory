require(stringi)
library(tm)
library(SnowballC)
hashtag_pattern <- "#([[:alnum:]]|[_])+"
mention_pattern <- "@([[:alnum:]]|[_])+"
strip_RT_pattern<-"RT\\s@([[:alnum:]]|[_])+:"
text<-gsub("<e4>","ä",text)
text<-gsub("<c4>","Ä",text)
text<-gsub("<d6>","Ö",text)
text<-gsub("<dc>","Ü",text)
text<-gsub("<f6>","ö",text)
text<-gsub("<fc>","ü",text)
text<-gsub("<df>","ss",text)
text<-gsub("ß","ss",text)
text<-gsub("<[^\\s]+>","",text)
text<-gsub("<[^\\s]+","",text)
text<-gsub("&amp;","",text)
text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",text)
text<-gsub("http.*[^\\s]+","",text)
text<-gsub("htt[p]?\U2026","",text)
text<-gsub("https","",text)
text<-gsub("http","",text)
text<-ifelse(grepl("\U2026",text),"",text)
#Die URLs und Mentions werden entfernt
text<-str_replace_all(text,pattern=mention_pattern,replacement="")
#Wörter die weniger als 3 Zeichen haben müssen weg außer sie haben #
text<-str_replace_all(text,pattern="(?<!#)\\b[a-zA-Z0-9]{1,2}\\b",replacement = "")
#depends on whether you wanna keep hashtags or not
text<-str_replace_all(text,pattern="#",replacement="")
#Konvertierung von Umlauten
text<-stri_replace_all_fixed(text,
#c("?", "?", "?", "?", "?", "?"),
c("\U00E4","\U00F6","\U00FC","\U00C4","\U00D6","\U00DC"),
c("ae", "oe", "ue", "Ae", "Oe", "Ue"), vectorize_all = FALSE)
#Zahlen außer IN Hashtags
text<-str_replace_all(text,pattern="\\b\\d+\\b",replacement="")
#Satzzeichen und Special Characters außer # müssen weg
text<-str_replace_all(text,pattern="[^[:alnum:]#]",replacement=" ")
text<-str_to_lower(text)
return(text)
}
stemTweetText<-function(text) {
require(stringr)
require(stringi)
library(tm)
library(SnowballC)
text<-strsplit(text," ")
words<-unlist(text)
words<-words[words!=""]
text<-wordStem(words,language="german")
text<-paste(text,collapse=" ")
return(text)
}
#checkCleaner<-c("This is a 💁 test #eu string .with @mention and #hashtag but d. u. also with http://www.ur.de !","And another string https://t.co/9aNUY4ZacF with to","we want; to keep #g20 or #r2g but, not 70 or 100 ...")
#cleanTweetText(checkCleaner)
twitter_data_sentiment<-read_delim("twitter data/SentimentAnalyse#1.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_david_snd<-read_delim("data/SentimentAnalyseDavidzweiterDurchlauf.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_jakob_snd<-read_delim("twitter data/SentimentAnalyse#2.csv",
";", escape_double = FALSE, trim_ws = TRUE,
locale = locale())
colnames(twitter_data_sentiment_david_snd)<-c("sentimentScore","text")
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(ID))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%select(-c(X1,ID,positveSentimentScore,negativeSentimentScore))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%filter(sentimentScore != "NA")
twitter_data_sentiment_jakob_snd$isMatch<-"1"
twitter_data_sentiment_david_snd$isMatch<-"1"
twitter_data_sentiment<-rbind(twitter_data_sentiment,twitter_data_sentiment_jakob_snd,twitter_data_sentiment_david_snd)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
twitter_data_sentiment<-twitter_data_sentiment%>%filter(sentimentScore != "NA")
twitter_data_sentiment<-twitter_data_sentiment%>%filter(text != "")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment$sentimentScore<-as.numeric(as.character(twitter_data_sentiment$sentimentScore))
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=stemTweetText(text))
twitter_data_sentiment$text[[1]]
twitter_data_sentiment<-read_delim("twitter data/SentimentAnalyse#1.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_david_snd<-read_delim("data/SentimentAnalyseDavidzweiterDurchlauf.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_jakob_snd<-read_delim("twitter data/SentimentAnalyse#2.csv",
";", escape_double = FALSE, trim_ws = TRUE,
locale = locale())
colnames(twitter_data_sentiment_david_snd)<-c("sentimentScore","text")
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(ID))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%select(-c(X1,ID,positveSentimentScore,negativeSentimentScore))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%filter(sentimentScore != "NA")
twitter_data_sentiment_jakob_snd$isMatch<-"1"
twitter_data_sentiment_david_snd$isMatch<-"1"
twitter_data_sentiment<-rbind(twitter_data_sentiment,twitter_data_sentiment_jakob_snd,twitter_data_sentiment_david_snd)
# Säubern
#twitter_data_sentiment$text<-gsub("<e4>","ä",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<c4>","Ä",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<d6>","Ö",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<dc>","Ü",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<f6>","ö",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<fc>","ü",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("ß","ss",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<[^\\s]+>","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<[^\\s]+","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("&amp;","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("https","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("http","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
twitter_data_sentiment<-twitter_data_sentiment%>%filter(sentimentScore != "NA")
twitter_data_sentiment<-twitter_data_sentiment%>%filter(text != "")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment$sentimentScore<-as.numeric(as.character(twitter_data_sentiment$sentimentScore))
# Nur Matches der Kreuzvalid.
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=stemTweetText(text))
require(tidyverse)
require(dplyr)
require(plyr)
library(readr)
library(SentimentAnalysis)
library(SnowballC)
library(tm)
library(spikeslab)
source("r scripts/cleanTweetText.R")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=stemTweetText(text))
cleanTweetText<-function(text){
require(stringr)
require(stringi)
library(tm)
library(SnowballC)
hashtag_pattern <- "#([[:alnum:]]|[_])+"
mention_pattern <- "@([[:alnum:]]|[_])+"
strip_RT_pattern<-"RT\\s@([[:alnum:]]|[_])+:"
text<-gsub("<e4>","ä",text)
text<-gsub("<c4>","Ä",text)
text<-gsub("<d6>","Ö",text)
text<-gsub("<dc>","Ü",text)
text<-gsub("<f6>","ö",text)
text<-gsub("<fc>","ü",text)
text<-gsub("<df>","ss",text)
text<-gsub("ß","ss",text)
text<-gsub("<[^\\s]+>","",text)
text<-gsub("<[^\\s]+","",text)
text<-gsub("&amp;","",text)
text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",text)
text<-gsub("http.*[^\\s]+","",text)
text<-gsub("htt[p]?\U2026","",text)
text<-gsub("https","",text)
text<-gsub("http","",text)
text<-ifelse(grepl("\U2026",text),"",text)
#Die URLs und Mentions werden entfernt
text<-str_replace_all(text,pattern=mention_pattern,replacement="")
#Wörter die weniger als 3 Zeichen haben müssen weg außer sie haben #
text<-str_replace_all(text,pattern="(?<!#)\\b[a-zA-Z0-9]{1,2}\\b",replacement = "")
#depends on whether you wanna keep hashtags or not
text<-str_replace_all(text,pattern="#",replacement="")
#Konvertierung von Umlauten
text<-stri_replace_all_fixed(text,
#c("?", "?", "?", "?", "?", "?"),
c("\U00E4","\U00F6","\U00FC","\U00C4","\U00D6","\U00DC"),
c("ae", "oe", "ue", "Ae", "Oe", "Ue"), vectorize_all = FALSE)
#Zahlen außer IN Hashtags
text<-str_replace_all(text,pattern="\\b\\d+\\b",replacement="")
#Satzzeichen und Special Characters außer # müssen weg
text<-str_replace_all(text,pattern="[^[:alnum:]#]",replacement=" ")
text<-str_to_lower(text)
return(text)
}
stemTweetText<-function(text) {
require(stringr)
require(stringi)
library(tm)
library(SnowballC)
text<-strsplit(text," ")
words<-unlist(text)
words<-words[words!=""]
text<-wordStem(words,language="german")
text<-paste(text,collapse=" ")
return(text)
}
#checkCleaner<-c("This is a 💁 test #eu string .with @mention and #hashtag but d. u. also with http://www.ur.de !","And another string https://t.co/9aNUY4ZacF with to","we want; to keep #g20 or #r2g but, not 70 or 100 ...")
#cleanTweetText(checkCleaner)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=stemTweetText(text))
cleanTweetText<-function(text){
require(stringr)
require(stringi)
library(tm)
library(SnowballC)
hashtag_pattern <- "#([[:alnum:]]|[_])+"
mention_pattern <- "@([[:alnum:]]|[_])+"
strip_RT_pattern<-"RT\\s@([[:alnum:]]|[_])+:"
text<-gsub("<e4>","ä",text)
text<-gsub("<c4>","Ä",text)
text<-gsub("<d6>","Ö",text)
text<-gsub("<dc>","Ü",text)
text<-gsub("<f6>","ö",text)
text<-gsub("<fc>","ü",text)
text<-gsub("<df>","ss",text)
text<-gsub("ß","ss",text)
text<-gsub("<[^\\s]+>","",text)
text<-gsub("<[^\\s]+","",text)
text<-gsub("&amp;","",text)
text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",text)
text<-gsub("http.*[^\\s]+","",text)
text<-gsub("htt[p]?\U2026","",text)
text<-gsub("https","",text)
text<-gsub("http","",text)
text<-ifelse(grepl("\U2026",text),"",text)
#Die URLs und Mentions werden entfernt
text<-str_replace_all(text,pattern=mention_pattern,replacement="")
#Wörter die weniger als 3 Zeichen haben müssen weg außer sie haben #
text<-str_replace_all(text,pattern="(?<!#)\\b[a-zA-Z0-9]{1,2}\\b",replacement = "")
#depends on whether you wanna keep hashtags or not
text<-str_replace_all(text,pattern="#",replacement="")
#Konvertierung von Umlauten
text<-stri_replace_all_fixed(text,
#c("?", "?", "?", "?", "?", "?"),
c("\U00E4","\U00F6","\U00FC","\U00C4","\U00D6","\U00DC"),
c("ae", "oe", "ue", "Ae", "Oe", "Ue"), vectorize_all = FALSE)
#Zahlen außer IN Hashtags
text<-str_replace_all(text,pattern="\\b\\d+\\b",replacement="")
#Satzzeichen und Special Characters außer # müssen weg
text<-str_replace_all(text,pattern="[^[:alnum:]#]",replacement=" ")
text<-str_to_lower(text)
return(text)
}
stemTweetText<-function(text) {
require(stringr)
require(stringi)
library(tm)
library(SnowballC)
text<-strsplit(text," ")
words<-unlist(text)
words<-words[words!=""]
words<-wordStem(words,language="german")
words<-paste(words,collapse=" ")
return(words)
}
#checkCleaner<-c("This is a 💁 test #eu string .with @mention and #hashtag but d. u. also with http://www.ur.de !","And another string https://t.co/9aNUY4ZacF with to","we want; to keep #g20 or #r2g but, not 70 or 100 ...")
#cleanTweetText(checkCleaner)
twitter_data_sentiment<-read_delim("twitter data/SentimentAnalyse#1.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_david_snd<-read_delim("data/SentimentAnalyseDavidzweiterDurchlauf.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_jakob_snd<-read_delim("twitter data/SentimentAnalyse#2.csv",
";", escape_double = FALSE, trim_ws = TRUE,
locale = locale())
colnames(twitter_data_sentiment_david_snd)<-c("sentimentScore","text")
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(ID))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%select(-c(X1,ID,positveSentimentScore,negativeSentimentScore))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%filter(sentimentScore != "NA")
twitter_data_sentiment_jakob_snd$isMatch<-"1"
twitter_data_sentiment_david_snd$isMatch<-"1"
twitter_data_sentiment<-rbind(twitter_data_sentiment,twitter_data_sentiment_jakob_snd,twitter_data_sentiment_david_snd)
# Säubern
#twitter_data_sentiment$text<-gsub("<e4>","ä",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<c4>","Ä",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<d6>","Ö",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<dc>","Ü",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<f6>","ö",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<fc>","ü",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("ß","ss",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<[^\\s]+>","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<[^\\s]+","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("&amp;","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("https","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("http","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
twitter_data_sentiment<-twitter_data_sentiment%>%filter(sentimentScore != "NA")
twitter_data_sentiment<-twitter_data_sentiment%>%filter(text != "")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment$sentimentScore<-as.numeric(as.character(twitter_data_sentiment$sentimentScore))
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=stemTweetText(text))
hi<-"hi hi hih hi hi hi"
ho<-"ho ho ho ho ohoho "
stemTweetText(hi)
stemTweetText(ho)
cleanTweetText<-function(text){
require(stringr)
require(stringi)
library(tm)
library(SnowballC)
hashtag_pattern <- "#([[:alnum:]]|[_])+"
mention_pattern <- "@([[:alnum:]]|[_])+"
strip_RT_pattern<-"RT\\s@([[:alnum:]]|[_])+:"
text<-gsub("<e4>","ä",text)
text<-gsub("<c4>","Ä",text)
text<-gsub("<d6>","Ö",text)
text<-gsub("<dc>","Ü",text)
text<-gsub("<f6>","ö",text)
text<-gsub("<fc>","ü",text)
text<-gsub("<df>","ss",text)
text<-gsub("ß","ss",text)
text<-gsub("<[^\\s]+>","",text)
text<-gsub("<[^\\s]+","",text)
text<-gsub("&amp;","",text)
text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",text)
text<-gsub("http.*[^\\s]+","",text)
text<-gsub("htt[p]?\U2026","",text)
text<-gsub("https","",text)
text<-gsub("http","",text)
text<-ifelse(grepl("\U2026",text),"",text)
#Die URLs und Mentions werden entfernt
text<-str_replace_all(text,pattern=mention_pattern,replacement="")
#Wörter die weniger als 3 Zeichen haben müssen weg außer sie haben #
text<-str_replace_all(text,pattern="(?<!#)\\b[a-zA-Z0-9]{1,2}\\b",replacement = "")
#depends on whether you wanna keep hashtags or not
text<-str_replace_all(text,pattern="#",replacement="")
#Konvertierung von Umlauten
text<-stri_replace_all_fixed(text,
#c("?", "?", "?", "?", "?", "?"),
c("\U00E4","\U00F6","\U00FC","\U00C4","\U00D6","\U00DC"),
c("ae", "oe", "ue", "Ae", "Oe", "Ue"), vectorize_all = FALSE)
#Zahlen außer IN Hashtags
text<-str_replace_all(text,pattern="\\b\\d+\\b",replacement="")
#Satzzeichen und Special Characters außer # müssen weg
text<-str_replace_all(text,pattern="[^[:alnum:]#]",replacement=" ")
text<-str_to_lower(text)
return(text)
}
stemTweetText<-function(text) {
require(stringr)
require(stringi)
library(tm)
library(SnowballC)
text<-as.character(text)
text<-strsplit(text," ")
words<-unlist(text)
words<-words[words!=""]
words<-wordStem(words,language="german")
words<-paste(words,collapse=" ")
return(words)
}
twitter_data_sentiment<-read_delim("twitter data/SentimentAnalyse#1.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_david_snd<-read_delim("data/SentimentAnalyseDavidzweiterDurchlauf.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_jakob_snd<-read_delim("twitter data/SentimentAnalyse#2.csv",
";", escape_double = FALSE, trim_ws = TRUE,
locale = locale())
colnames(twitter_data_sentiment_david_snd)<-c("sentimentScore","text")
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(ID))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%select(-c(X1,ID,positveSentimentScore,negativeSentimentScore))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%filter(sentimentScore != "NA")
twitter_data_sentiment_jakob_snd$isMatch<-"1"
twitter_data_sentiment_david_snd$isMatch<-"1"
twitter_data_sentiment<-rbind(twitter_data_sentiment,twitter_data_sentiment_jakob_snd,twitter_data_sentiment_david_snd)
# Säubern
#twitter_data_sentiment$text<-gsub("<e4>","ä",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<c4>","Ä",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<d6>","Ö",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<dc>","Ü",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<f6>","ö",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<fc>","ü",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("ß","ss",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<[^\\s]+>","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<[^\\s]+","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("&amp;","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("https","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("http","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
twitter_data_sentiment<-twitter_data_sentiment%>%filter(sentimentScore != "NA")
twitter_data_sentiment<-twitter_data_sentiment%>%filter(text != "")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment$sentimentScore<-as.numeric(as.character(twitter_data_sentiment$sentimentScore))
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=stemTweetText(text))
apply(twitter_data_sentiment[,"text"],1,function(x) stemTweetText(x))
twitter_data_sentiment<-read_delim("twitter data/SentimentAnalyse#1.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_david_snd<-read_delim("data/SentimentAnalyseDavidzweiterDurchlauf.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_jakob_snd<-read_delim("twitter data/SentimentAnalyse#2.csv",
";", escape_double = FALSE, trim_ws = TRUE,
locale = locale())
colnames(twitter_data_sentiment_david_snd)<-c("sentimentScore","text")
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(ID))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%select(-c(X1,ID,positveSentimentScore,negativeSentimentScore))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%filter(sentimentScore != "NA")
twitter_data_sentiment_jakob_snd$isMatch<-"1"
twitter_data_sentiment_david_snd$isMatch<-"1"
twitter_data_sentiment<-rbind(twitter_data_sentiment,twitter_data_sentiment_jakob_snd,twitter_data_sentiment_david_snd)
# Säubern
#twitter_data_sentiment$text<-gsub("<e4>","ä",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<c4>","Ä",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<d6>","Ö",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<dc>","Ü",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<f6>","ö",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<fc>","ü",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("ß","ss",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<[^\\s]+>","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("<[^\\s]+","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("&amp;","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("http[s]?\\://t\\.co/[^ ]{10}","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("http.*[^\\s]+","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("htt[p]?\U2026","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("https","",twitter_data_sentiment$text)
#twitter_data_sentiment$text<-gsub("http","",twitter_data_sentiment$text)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
twitter_data_sentiment<-twitter_data_sentiment%>%filter(sentimentScore != "NA")
twitter_data_sentiment<-twitter_data_sentiment%>%filter(text != "")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment$sentimentScore<-as.numeric(as.character(twitter_data_sentiment$sentimentScore))
apply(twitter_data_sentiment[,"text"],1,function(x) stemTweetText(x))
twitter_data_sentiment$text<-apply(twitter_data_sentiment[,"text"],1,function(x) stemTweetText(x))
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_5lvl<-twitter_data_sentiment_match
twitter_data_sentiment_5lvl<-twitter_data_sentiment_5lvl%>%select("sentimentScore", "text")
x5<-transformIntoCorpus(twitter_data_sentiment_5lvl$text)
xDTM5<-toDocumentTermMatrix(x5, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE)
response5<-twitter_data_sentiment_5lvl$sentimentScore
dict_lasso5<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
summary(dict_lasso5)
dict_lasso5
twitter_data_sentiment_5lvl<-twitter_data_sentiment_match
twitter_data_sentiment_5lvl<-twitter_data_sentiment_5lvl%>%select("sentimentScore", "text")
#write.csv(twitter_data_sentiment_5lvl, "data/SentimentAnalyse_5LevelDict")
x5<-transformIntoCorpus(twitter_data_sentiment_5lvl$text)
xDTM5<-toDocumentTermMatrix(x5, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE)
response5<-twitter_data_sentiment_5lvl$sentimentScore
dict_lasso5<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
dict_lm5<-generateDictionary(xDTM5,response5,modelType = "lm", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_enet5<-generateDictionary(xDTM5,response5,modelType = "enet", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
dict_ridge5<-generateDictionary(xDTM5,response5,modelType = "ridge", filterTerms = NULL, control = list(), sparsity = 0.99999999, weighting= function(x)
tm::weightTfIdf(x, normalize = TRUE), language = "german")
source("r scripts/cleanTweetText.R")
require(tidyverse)
require(dplyr)
require(plyr)
library(readr)
twitter_data<-read_csv("twitter data/twitter_data.csv",
locale = locale())
# Aufbereiten Twitter Datensatz
twitter_data<-twitter_data%>%filter(lang=="de" | lang == "da")
#Entfernt alle Links (http(s) und alle Zeichen bis zum nächsten Leerzeichen)
twitter_data$text<-gsub("http[s]?://t\\.co/[^ ]{10}","",twitter_data$text)
twitter_data$text<-gsub("http.*[^\\s]+","",twitter_data$text)
twitter_data$text<-gsub("https","",twitter_data$text)
twitter_data$text<-gsub("http","",twitter_data$text)
#Entfernt alle abgeschnittenen Links
twitter_data$text<-gsub("htt[p]?\U2026","",twitter_data$text)
#Entfernen von abgeschnittenen Tweets
twitter_data<-twitter_data[!grepl("\U2026", twitter_data$text),]
#CleanTweetText auf den gesamten Twitter Datensatz
twitter_data<-twitter_data%>%mutate(text=cleanTweetText(text))
summary(dict_lm5)
plot(dict_lm5)
plot(dict_lasso5)
summary(dict_enet5)
plot(dict_enet5)
summary(dict_ridge5)
plot(dict_ridge5)
twitter_data$text<-apply(twitter_data[,"text"],1,function(x) stemTweetText(x))
test_documents<-twitter_data_sentiment_match$text
pred<-predict(dict_lasso5,test_documents)
test_documents<-twitter_data_sentiment_5lvl$text
test_response<-twitter_data_sentiment_5lvl$sentimentScore
pred<-predict(dict_lasso5,test_documents)
compareToResponse(pred,test_response)
twitter_data_sentiment<-read_delim("twitter data/SentimentAnalyse#1.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_david_snd<-read_delim("data/SentimentAnalyseDavidzweiterDurchlauf.csv",";"
,escape_double = FALSE, trim_ws =TRUE,
locale = locale())
twitter_data_sentiment_jakob_snd<-read_delim("twitter data/SentimentAnalyse#2.csv",
";", escape_double = FALSE, trim_ws = TRUE,
locale = locale())
colnames(twitter_data_sentiment_david_snd)<-c("sentimentScore","text")
twitter_data_sentiment<-twitter_data_sentiment%>%select(-c(ID))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%select(-c(X1,ID,positveSentimentScore,negativeSentimentScore))
twitter_data_sentiment_jakob_snd<-twitter_data_sentiment_jakob_snd%>%filter(sentimentScore != "NA")
twitter_data_sentiment_jakob_snd$isMatch<-"1"
twitter_data_sentiment_david_snd$isMatch<-"1"
twitter_data_sentiment<-rbind(twitter_data_sentiment,twitter_data_sentiment_jakob_snd,twitter_data_sentiment_david_snd)
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(text=cleanTweetText(text))
# Umwandeln der Scores in numeric mit "."
twitter_data_sentiment<-twitter_data_sentiment%>%filter(sentimentScore != "NA")
twitter_data_sentiment<-twitter_data_sentiment%>%filter(text != "")
twitter_data_sentiment<-twitter_data_sentiment%>%mutate(sentimentScore = sub(",", ".", sentimentScore, fixed = TRUE))
twitter_data_sentiment$sentimentScore<-as.numeric(as.character(twitter_data_sentiment$sentimentScore))
twitter_data_sentiment_match<-twitter_data_sentiment%>%filter(isMatch =="1")
twitter_data_sentiment_5lvl<-twitter_data_sentiment_match
twitter_data_sentiment_5lvl<-twitter_data_sentiment_5lvl%>%select("sentimentScore", "text")
#write.csv(twitter_data_sentiment_5lvl, "data/SentimentAnalyse_5LevelDict")
x5<-transformIntoCorpus(twitter_data_sentiment_5lvl$text)
xDTM5<-toDocumentTermMatrix(x5, language = "german", minWordLength = 3,
sparsity = NULL, removeStopwords = TRUE, stemming = FALSE)
response5<-twitter_data_sentiment_5lvl$sentimentScore
dict_lasso5<-generateDictionary(xDTM5,response5,modelType = "lasso", sparsity = 0.99999999, language = "german")
test_documents<-twitter_data_sentiment_5lvl$text
test_response<-twitter_data_sentiment_5lvl$sentimentScore
pred<-predict(dict_lasso5,test_documents)
compareToResponse(pred,test_response)
